{
 "metadata": {
  "name": "",
  "signature": "sha256:a38b405b5424bfc2a0941846e7522bcd39abc8195ecc2516d845c9c54a800ab2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import pystan\n",
      "import matplotlib.pyplot as plt\n",
      "import argparse\n",
      "\n",
      "nneuron = 61\n",
      "min_angle = -90\n",
      "max_angle = 90\n",
      "sprefs = np.linspace(min_angle, max_angle, nneuron)\n",
      "ndata = 3000\n",
      "eps = np.finfo(np.float64).eps\n",
      "\n",
      "r_max = 10\n",
      "sigtc_sq = float(10**2)\n",
      "sigtc = 10\n",
      "c_50 = 13.1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def random_s(ndata, sort):\n",
      "    s = np.random.rand(2, ndata) * 120 - 60\n",
      "    if sort:\n",
      "        s = np.sort(s, axis=0)\n",
      "    return s[0], s[1]\n",
      "\n",
      "def generate_trainset(ndata, r_max=10):\n",
      "    s_0, s_1 = random_s(ndata, True)\n",
      "    c_0, c_1 = np.ones((2, ndata)) * .5\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c\n",
      "\n",
      "def generate_s1set(ndata):\n",
      "    s_0, s_1 = random_s(ndata, True)\n",
      "    c_0 = np.ones(ndata)\n",
      "    c_1 = np.zeros(ndata)\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c\n",
      "    \n",
      "def generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, noise, sort, s_0, s_1, c_0, c_1):\n",
      "    c_rms = np.sqrt(np.square(c_0) + np.square(c_1))\n",
      "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
      "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
      "    stim_0 = c_0 * s_0t.T\n",
      "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
      "    stim_1 = c_1 * s_1t.T\n",
      "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
      "    r = r_max * (stim_0 + stim_1)\n",
      "    r = r.T\n",
      "    s = np.array((s_0, s_1)).T\n",
      "    s = s/90\n",
      "    c = np.array((c_0, c_1)).T\n",
      "    if noise == \"poisson\":\n",
      "        r = np.random.poisson(r) + 0.0\n",
      "    return r, s, c\n",
      "\n",
      "def generate_s_data(stim_0, stim_1, ndata, con_0=.5, con_1=.5, r_max=10):\n",
      "    #c_0, c_1 = np.ones((2, ndata)) * .5\n",
      "    c_0 = np.ones(ndata) * con_0\n",
      "    c_1 = np.ones(ndata) * con_1\n",
      "    s_0, s_1 = np.ones((2, ndata))\n",
      "    s_0 = s_0 * stim_0\n",
      "    s_1 = s_1 * stim_1\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neurons_code = \"\"\"\n",
      "    data {\n",
      "        int<lower=0> N; // number of neurons\n",
      "        int r[N]; // neural response\n",
      "        real sprefs[N]; // preferred stimuli\n",
      "        real<lower=0> c_1;\n",
      "        real<lower=0> c_2;\n",
      "        int r_max;\n",
      "        //real c_rms;\n",
      "        //real c_50;\n",
      "        //real<lower=0> sig_tc;\n",
      "        real<lower=0> sigtc_sq;\n",
      "    }\n",
      "    parameters {\n",
      "        real s_1;\n",
      "        //real s_2;\n",
      "        real<lower=s_1> s_2;\n",
      "    }\n",
      "    transformed parameters {\n",
      "        real lambda[N];\n",
      "        for (n in 1:N)\n",
      "            // lambda[n] <- r_max * ((c_1 * exp(normal_log(s_1, sprefs[n], sig_tc)) + c_2 * exp(normal_log(s_2, sprefs[n], sig_tc)))/(c_rms + c_50));\n",
      "            // lambda[n] <- r_max * (c_1 * exp(normal_log(s_1, sprefs[n], sig_tc)) + c_2 * exp(normal_log(s_2, sprefs[n], sig_tc)));\n",
      "            lambda[n] <- r_max * (c_1 * exp(- square(s_1 - sprefs[n])/(2 * sigtc_sq)) + c_2 * exp(- square(s_2 - sprefs[n])/(2 * sigtc_sq)));\n",
      "    }\n",
      "    model {\n",
      "        s_1 ~ uniform(-60, 60);\n",
      "        //s_2 ~ uniform(-60, 60);\n",
      "        s_2 ~ uniform(s_1, 60);\n",
      "        r ~ poisson(lambda);\n",
      "    }\n",
      "    \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fisher_inf(s_0, s_1, c_0, c_1, r_max=10):\n",
      "    fs_0 = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs))/(2 * sigtc_sq))[0]\n",
      "    qs_0 = r_max * c_0 * fs_0\n",
      "    df_s0 = ((-s_0 + sprefs)/sigtc_sq) * qs_0\n",
      "    fs_1 = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs))/(2 * sigtc_sq))[0]\n",
      "    qs_1 = r_max * c_1 * fs_1\n",
      "    df_s1 = ((-s_1 + sprefs)/sigtc_sq) * qs_1\n",
      "    Q = qs_0 + qs_1\n",
      "    Q_inv = 1/Q\n",
      "    J_11 = np.sum(np.square(df_s0) * Q_inv)\n",
      "    J_22 = np.sum(np.square(df_s1) * Q_inv)\n",
      "    J_12 = J_21 = np.sum(df_s0 * df_s1 * Q_inv)\n",
      "    fisher = np.linalg.inv([[J_11, J_12], [J_21, J_22]])\n",
      "    return fisher\n",
      "\n",
      "def fit_optimal(r, sm, s=None, N=61, init=None, sprefs=sprefs, sampling=False, sort=False, c_1=.5, c_2=.5, c_50=13.1, r_max=10, c_rms=0.707106781, sig_tc=10, sigtc_sq=10**2):\n",
      "    ndata = len(r)\n",
      "    neurons_dat = {'N': 61,\n",
      "                   'r': r[0].astype(int),\n",
      "                   'sprefs': sprefs,\n",
      "                   'c_1': .5,\n",
      "                   'c_2': .5,\n",
      "                   'c_50': 13.1,\n",
      "                   'r_max': r_max,\n",
      "                   'c_rms': 0.707106781,\n",
      "                   'sig_tc': 10,\n",
      "                   'sigtc_sq': sigtc_sq}\n",
      "\n",
      "    optimal = np.zeros((2, ndata))\n",
      "    print init\n",
      "    for i in range(len(r)):\n",
      "        neurons_dat['r'] = r[i].astype(int)\n",
      "        if sampling:\n",
      "            op = sm.sampling(data=neurons_dat)\n",
      "            optimal[0][i], optimal[1][i] = np.mean(op['s_1']), np.mean(op['s_2'])\n",
      "        else:\n",
      "            if s.any():\n",
      "                init = {'s_1':max(s[0][i], -60 + eps), 's_2':min(s[1][i] + eps, 60 - eps)}\n",
      "                print init\n",
      "                op = sm.optimizing(data=neurons_dat, init=init)\n",
      "            elif not init:\n",
      "                op = sm.optimizing(data=neurons_dat)\n",
      "            else:     \n",
      "                op = sm.optimizing(data=neurons_dat, init=init)\n",
      "            optimal[0][i], optimal[1][i] = op['s_1'], op['s_2']\n",
      "        if sort:\n",
      "            optimal = np.sort(optimal, axis=0)\n",
      "    return optimal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Multilayer ReLU net\n",
      "\"\"\"\n",
      "\n",
      "def relu(x):\n",
      "    return theano.tensor.switch(x<0, 0, x)\n",
      "\n",
      "class HiddenLayer(object):\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None,\n",
      "                 activation=T.nnet.sigmoid):\n",
      "        \"\"\"\n",
      "        Typical hidden layer of a MLP: units are fully-connected and have\n",
      "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
      "        and the bias vector b is of shape (n_out,).\n",
      "\n",
      "        :type rng: np.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.dmatrix\n",
      "        :param input: a symbolic tensor of shape (n_examples, n_in)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: dimensionality of input\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of hidden units\n",
      "\n",
      "        :type activation: theano.Op or function\n",
      "        :param activation: Non linearity to be applied in the hidden\n",
      "                           layer\n",
      "        \"\"\"\n",
      "        self.input = input\n",
      "        if W is None:\n",
      "            W_values = (1/np.sqrt(n_in)) * np.random.randn(n_in, n_out)\n",
      "            \n",
      "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
      "\n",
      "        if b is None:\n",
      "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
      "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
      "\n",
      "        self.W = W\n",
      "        self.b = b\n",
      "\n",
      "        lin_output = T.dot(input, self.W) + self.b\n",
      "        self.output = (\n",
      "            lin_output if activation is None\n",
      "            else activation(lin_output)\n",
      "        )\n",
      "        # parameters of the model\n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "class COMLayer(object):\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None):\n",
      "        \"\"\"\n",
      "        Layer with Center of Mass decoder\n",
      "        Params same as above\n",
      "        \"\"\"\n",
      "        self.input = input\n",
      "        if W is None:\n",
      "            W_values = (1/np.sqrt(n_in)) * np.random.randn(n_in, n_out)\n",
      "\n",
      "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
      "\n",
      "        self.W = W\n",
      "        \n",
      "        self.ones = np.ones((n_in, n_out))\n",
      "        \n",
      "        self.output = T.dot(input, self.W)/T.dot(input, self.ones)\n",
      "        \n",
      "        # parameters of the model\n",
      "        self.params = [self.W]\n",
      "\n",
      "class MLP(object):\n",
      "\n",
      "\n",
      "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
      "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
      "\n",
      "        :type rng: np.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.TensorType\n",
      "        :param input: symbolic variable that describes the input of the\n",
      "        architecture (one minibatch)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: number of input units, the dimension of the space in\n",
      "        which the datapoints lie\n",
      "\n",
      "        :type n_hidden: int\n",
      "        :param n_hidden: number of hidden units\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of output units, the dimension of the space in\n",
      "        which the labels lie\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        self.hiddenLayer1 = HiddenLayer(\n",
      "            rng=rng,\n",
      "            input=input,\n",
      "            n_in=n_in,\n",
      "            n_out=n_hidden,\n",
      "            #activation=T.nnet.sigmoid\n",
      "            activation=relu\n",
      "        )\n",
      "        \n",
      "        self.hiddenLayer2 = HiddenLayer(\n",
      "            rng=rng,\n",
      "            input=self.hiddenLayer1.output,\n",
      "            n_in=n_hidden,\n",
      "            n_out=n_out,\n",
      "            #activation=relu\n",
      "            activation=None\n",
      "        )\n",
      "        \n",
      "        self.y_pred = self.hiddenLayer2.output\n",
      "        \n",
      "        # the parameters of the model are the parameters of the two layers it is made out of\n",
      "        self.params = self.hiddenLayer1.params + self.hiddenLayer2.params\n",
      "    \n",
      "    def get_params(self):\n",
      "\n",
      "        params = {}\n",
      "        for param in self.params:\n",
      "            name = param.name\n",
      "            if name in params:\n",
      "                name = name, 2\n",
      "            params[name] = param.get_value()\n",
      "        return params\n",
      "    \n",
      "    def mse(self, y):\n",
      "        # error between output and target\n",
      "        return T.mean((self.y_pred[0] - y[0]) ** 2 + (self.y_pred[1] - y[1]) ** 2)\n",
      "    \n",
      "    def mse_s1(self, y):\n",
      "        # error between output and target\n",
      "        return T.mean((self.y_pred[0] - y[0]) ** 2)\n",
      "    \n",
      "    def valid_mse(self, y):\n",
      "        return T.mean(((self.y_pred[0] * 90) - (y[0] * 90)) ** 2 + ((self.y_pred[1] * 90) - (y[1] * 90)) ** 2)\n",
      "    \n",
      "    def sym_mse(self, y):\n",
      "        # error between output and target\n",
      "        return T.mean(((self.y_pred[0] - y[0]) ** 2 + (self.y_pred[1] - y[1]) ** 2)\n",
      "                      * ((self.y_pred[1] - y[0]) ** 2 + (self.y_pred[0] - y[1]) ** 2))\n",
      "        \n",
      "class COMMLP(object):\n",
      "\n",
      "\n",
      "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
      "        \"\"\"\n",
      "        Params same as above\n",
      "        \"\"\"\n",
      "\n",
      "        self.hiddenLayer1 = HiddenLayer(\n",
      "            rng=rng,\n",
      "            input=input,\n",
      "            n_in=n_in,\n",
      "            n_out=n_hidden,\n",
      "            activation=T.nnet.sigmoid\n",
      "        )\n",
      "        \n",
      "        self.hiddenLayer2 = COMLayer(\n",
      "            rng=rng,\n",
      "            input=self.hiddenLayer1.output,\n",
      "            n_in=n_hidden,\n",
      "            n_out=n_out,\n",
      "        )\n",
      "        \n",
      "        self.y_pred = self.hiddenLayer2.output\n",
      "        \n",
      "        # the parameters of the model are the parameters of the two layers it is made out of\n",
      "        self.params = self.hiddenLayer1.params + self.hiddenLayer2.params\n",
      "    \n",
      "    def get_params(self):\n",
      "        params = {}\n",
      "        for param in self.params:\n",
      "            name = param.name\n",
      "            if name in params:\n",
      "                name = name, 2\n",
      "            params[name] = param.get_value()\n",
      "        return params\n",
      "    \n",
      "    def mse(self, y):\n",
      "        # error between output and target\n",
      "        return T.mean((self.y_pred[0] - y[0]) ** 2 + (self.y_pred[1] - y[1]) ** 2)\n",
      "    \n",
      "    def sym_mse(self, y):\n",
      "        # error between output and target\n",
      "        return T.mean(((self.y_pred[0] - y[0]) ** 2 + (self.y_pred[1] - y[1]) ** 2)\n",
      "                      * ((self.y_pred[1] - y[0]) ** 2 + (self.y_pred[0] - y[1]) ** 2))\n",
      "        \n",
      "\n",
      "def shared_dataset(data_xy, borrow=True):\n",
      "        \"\"\" Function that loads the dataset into shared variables\n",
      "        \"\"\"\n",
      "        data_x, data_y, _ = data_xy\n",
      "        shared_x = theano.shared(np.asarray(data_x,\n",
      "                                               dtype='float32'),\n",
      "                                 borrow=borrow)\n",
      "        shared_y = theano.shared(np.asarray(data_y,\n",
      "                                               dtype='float32'),\n",
      "                                 borrow=borrow)\n",
      "        return shared_x, shared_y\n",
      "\n",
      "def train_nn(train_dataset, valid_dataset=None, n_hidden=20, learning_rate=0.01, n_epochs=10, batch_size=20, test_data=None, COM=False, RMSProp=False, nesterov=True, momentum=0, n_in=61, n_out=2):\n",
      "    \"\"\"\n",
      "    Demonstrate stochastic gradient descent optimization for a multilayer\n",
      "    perceptron\n",
      "\n",
      "    :type learning_rate: float\n",
      "    :param learning_rate: learning rate used (factor for the stochastic\n",
      "    gradient\n",
      "\n",
      "    :type n_epochs: int\n",
      "    :param n_epochs: maximal number of epochs to run the optimizer\n",
      "\n",
      "   \"\"\"\n",
      "    train_set_x, train_set_y = shared_dataset(train_dataset)\n",
      "    if valid_dataset:\n",
      "        valid_set_x, valid_set_y = shared_dataset(valid_dataset)\n",
      "\n",
      "    # compute number of minibatches for training, validation and testing\n",
      "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "    n_valid_batches = n_train_batches\n",
      "    \n",
      "    \n",
      "    ######################\n",
      "    # BUILD ACTUAL MODEL #\n",
      "    ######################\n",
      "    print '... building the model'\n",
      "\n",
      "    # allocate symbolic variables for the data\n",
      "    index = T.lscalar()  # index to a [mini]batch\n",
      "    x = T.fmatrix('x')   # input data from visual neurons\n",
      "    y = T.fmatrix('y')  # posterior\n",
      "\n",
      "    rng = np.random.RandomState(1234)\n",
      "\n",
      "    # construct the MLP class\n",
      "    nn = MLP(rng=rng, input=x, n_in=n_in, n_hidden=n_hidden, n_out=n_out)\n",
      "    \n",
      "    if COM:\n",
      "        nn = COMMLP(rng=rng, input=x, n_in=n_in, n_hidden=n_hidden, n_out=n_out)\n",
      "    else:\n",
      "        nn = MLP(rng=rng, input=x, n_in=n_in, n_hidden=n_hidden, n_out=n_out)\n",
      "\n",
      "    cost = nn.mse(y)\n",
      "    \n",
      "    def RMSprop(cost, params, learning_rate=0.001, rho=0.9, epsilon=1e-6, mu=0, nesterov=False):\n",
      "        gparams = T.grad(cost, params)\n",
      "        updates = []\n",
      "        for p, g in zip(params, gparams):\n",
      "            v = theano.shared(p.get_value() * 0.)\n",
      "            ms = theano.shared(p.get_value() * 0.)\n",
      "            ms_new = rho * ms + (1 - rho) * g ** 2\n",
      "            gradient_scaling = T.sqrt(ms_new + epsilon)\n",
      "            g = g / gradient_scaling\n",
      "            \"\"\"\n",
      "            (1) v_t = mu * v_t-1 - lr * gradient_f(params_t)\n",
      "            or\n",
      "            classic\n",
      "            (2) params_t = params_t-1 + v_t\n",
      "            nesterov\n",
      "            (7) params_t = params_t-1 + mu * v_t - lr * gradient_f(params_t-1)\n",
      "            (8) params_t = params_t-1 + mu**2 * v_t-1 - (1+mu) * lr * gradient_f(params_t-1)\n",
      "            \"\"\"\n",
      "            v_new = mu * v - (1 - mu) * learning_rate * g\n",
      "            if nesterov:\n",
      "                p_new = p + mu * v_new - (1 - mu) * learning_rate * g\n",
      "            else:\n",
      "                p_new = p + v_new\n",
      "            updates.append((ms, ms_new))\n",
      "            updates.append((v, v_new))\n",
      "            updates.append((p, p_new))\n",
      "                \n",
      "        return updates\n",
      "    \n",
      "    if RMSProp:\n",
      "        updates = RMSprop(cost, nn.params, learning_rate=learning_rate, mu=momentum, nesterov=nesterov)\n",
      "    else:\n",
      "        # compute the gradient of cost with respect to theta (sotred in params)\n",
      "        # the resulting gradients will be stored in a list gparams\n",
      "        gparams = [T.grad(cost, param) for param in nn.params]\n",
      "\n",
      "        # specify how to update the parameters of the model as a list of\n",
      "        # (variable, update expression) pairs\n",
      "\n",
      "        updates = [\n",
      "            (param, param - learning_rate * gparam)\n",
      "            for param, gparam in zip(nn.params, gparams)\n",
      "        ]\n",
      "    \n",
      "    def inspect_inputs(i, node, fn):\n",
      "        print i, node, \"input(s) value(s):\", [input[0] for input in fn.inputs]\n",
      "\n",
      "    def inspect_outputs(i, node, fn):\n",
      "        print \"output(s) value(s):\", [output[0] for output in fn.outputs]\n",
      "\n",
      "    # compiling a Theano function `train_model` that returns the cost, but\n",
      "    # in the same time updates the parameter of the model based on the rules\n",
      "    # defined in `updates`\n",
      "    train_model = theano.function(\n",
      "        inputs=[index],\n",
      "        outputs=cost,\n",
      "        updates=updates,\n",
      "        givens={\n",
      "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
      "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
      "        }\n",
      "    )\n",
      "    \n",
      "    validate_model = theano.function(\n",
      "        inputs=[index],\n",
      "        outputs=nn.valid_mse(y),\n",
      "        givens={\n",
      "            x: valid_set_x[index * batch_size:(index + 1) * batch_size],\n",
      "            y: valid_set_y[index * batch_size:(index + 1) * batch_size]\n",
      "        }\n",
      "    )\n",
      "\n",
      "    ###############\n",
      "    # TRAIN MODEL #\n",
      "    ###############\n",
      "    print '... training'\n",
      "\n",
      "    start_time = time.clock()\n",
      "\n",
      "    epoch = 0 \n",
      "    done_looping = False\n",
      "    \n",
      "    if valid_dataset:\n",
      "        valid_mse = np.zeros(n_epochs)\n",
      "\n",
      "    while (epoch < n_epochs) and (not done_looping):\n",
      "        for minibatch_index in xrange(n_train_batches):\n",
      "            \n",
      "            minibatch_avg_cost = train_model(minibatch_index)\n",
      "            \n",
      "        if valid_dataset:\n",
      "            validation_losses = [validate_model(i) for i in xrange(n_valid_batches)]\n",
      "            this_validation_loss = np.mean(validation_losses)\n",
      "            valid_mse[epoch] = this_validation_loss \n",
      "\n",
      "            print(\n",
      "                'epoch %i, minibatch %i/%i, validation error %f' %\n",
      "                (\n",
      "                    epoch,\n",
      "                    minibatch_index + 1,\n",
      "                    n_train_batches,\n",
      "                    this_validation_loss\n",
      "                )\n",
      "            )\n",
      "            \n",
      "        epoch = epoch + 1\n",
      "\n",
      "    end_time = time.clock()\n",
      "    \n",
      "    if valid_dataset:\n",
      "        return nn, x, valid_mse\n",
      "    return nn, x\n",
      "\n",
      "def test_nn(nn, nnx, test_data):\n",
      "    print 'testing'\n",
      "    test_batch_size = 1\n",
      "    test_set_x, test_set_y = shared_dataset(test_data)\n",
      "    index = T.lscalar()  # index to a [mini]batch\n",
      "    x = nnx   # input data from visual neurons\n",
      "    test_model = theano.function(\n",
      "        inputs=[index],\n",
      "        outputs=nn.y_pred,\n",
      "        givens={\n",
      "            x: test_set_x[index * test_batch_size: (index + 1) * test_batch_size]\n",
      "        },\n",
      "    )\n",
      "    \n",
      "    true_ys = test_set_y.get_value()\n",
      "    pred_ys = np.zeros((len(true_ys), 2))\n",
      "    for i in range(len(true_ys)):\n",
      "        pred_ys[i] = test_model(i)\n",
      "        #print test_model(i)[0], true_ys[i]\n",
      "        #print test_model(i)[0] * 90, true_ys[i]\n",
      "    \n",
      "    #print nn.get_params()\n",
      "    return pred_ys, true_ys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Setting up models\n",
      "sm = pystan.StanModel(model_code=neurons_code)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_statistics(s1, s2, preds):\n",
      "    mean_s1 = np.mean(preds[0])\n",
      "    mean_s2 = np.mean(preds[1])\n",
      "    bias_s1 = mean_s1 - s1\n",
      "    bias_s2 = mean_s2 - s2\n",
      "    covmat = np.cov(preds)\n",
      "    var_s1 = covmat[0, 0]\n",
      "    var_s2 = covmat[1, 1]\n",
      "    cov = covmat[0, 1]\n",
      "    corr = cov / (np.sqrt(var_s1) * np.sqrt(var_s2))\n",
      "    stats = {'mean_s1': mean_s1, 'mean_s2': mean_s2, 'bias_s1': bias_s1, 'bias_s2': bias_s2, 'var_s1': var_s1, 'var_s2': var_s2, 'cov': cov, 'corr': corr}\n",
      "    return stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data_1 = generate_trainset(20000)\n",
      "valid_data_1 = generate_trainset(20000)\n",
      "nn_rms, nnx_rms, valid_mse_rms = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.001, n_epochs=100, RMSProp=True)\n",
      "\"\"\"\n",
      "nn_rms_m9, nnx_rms_m9, valid_mse_rms_m9 = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.001, n_epochs=100, RMSProp=True, nesterov=True, momentum=0.9)\n",
      "nn_rms_m9f, nnx_rms_m9f, valid_mse_rms_m9f = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.001, n_epochs=100, RMSProp=True, nesterov=False, momentum=0.9)\n",
      "nn_rms_m95, nnx_rms_m95, valid_mse_rms_m95 = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.001, n_epochs=100, RMSProp=True, momentum=0.95)\n",
      "nn_rms_m99, nnx_rms_m99, valid_mse_rms_m99 = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.001, n_epochs=100, RMSProp=True, momentum=0.99)\n",
      "\"\"\"\n",
      "nn_plain, nnx_plain, valid_mse_plain = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.001, n_epochs=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... building the model\n",
        "... training"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 0, minibatch 1000/1000, validation error 413.844599"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 1, minibatch 1000/1000, validation error 158.038987"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2, minibatch 1000/1000, validation error 98.882624"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3, minibatch 1000/1000, validation error 85.494508"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4, minibatch 1000/1000, validation error 79.606925"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5, minibatch 1000/1000, validation error 68.514388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6, minibatch 1000/1000, validation error 61.979155"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7, minibatch 1000/1000, validation error 58.171097"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8, minibatch 1000/1000, validation error 55.437150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9, minibatch 1000/1000, validation error 54.078948"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10, minibatch 1000/1000, validation error 52.776041"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11, minibatch 1000/1000, validation error 51.282774"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12, minibatch 1000/1000, validation error 49.482726"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13, minibatch 1000/1000, validation error 48.927032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14, minibatch 1000/1000, validation error 47.931446"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15, minibatch 1000/1000, validation error 47.838384"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16, minibatch 1000/1000, validation error 47.411115"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17, minibatch 1000/1000, validation error 47.859582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18, minibatch 1000/1000, validation error 48.864084"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19, minibatch 1000/1000, validation error 48.979961"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20, minibatch 1000/1000, validation error 52.163021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 21, minibatch 1000/1000, validation error 52.926117"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 22, minibatch 1000/1000, validation error 51.483095"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 23, minibatch 1000/1000, validation error 51.383577"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 24, minibatch 1000/1000, validation error 50.435413"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 25, minibatch 1000/1000, validation error 50.009081"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 26, minibatch 1000/1000, validation error 50.627275"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 27, minibatch 1000/1000, validation error 49.782910"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 28, minibatch 1000/1000, validation error 49.151109"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 29, minibatch 1000/1000, validation error 48.921266"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 30, minibatch 1000/1000, validation error 50.053929"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 31, minibatch 1000/1000, validation error 49.817879"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 32, minibatch 1000/1000, validation error 49.837032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 33, minibatch 1000/1000, validation error 50.676305"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 34, minibatch 1000/1000, validation error 50.317588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 35, minibatch 1000/1000, validation error 50.746188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 36, minibatch 1000/1000, validation error 50.871923"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 37, minibatch 1000/1000, validation error 50.728870"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 38, minibatch 1000/1000, validation error 50.322693"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 39, minibatch 1000/1000, validation error 50.188253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 40, minibatch 1000/1000, validation error 50.187255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 41, minibatch 1000/1000, validation error 50.116281"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 42, minibatch 1000/1000, validation error 49.763969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 43, minibatch 1000/1000, validation error 50.106286"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 44, minibatch 1000/1000, validation error 50.072234"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 45, minibatch 1000/1000, validation error 49.991580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 46, minibatch 1000/1000, validation error 49.447463"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 47, minibatch 1000/1000, validation error 49.391634"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 48, minibatch 1000/1000, validation error 48.748883"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 49, minibatch 1000/1000, validation error 48.540010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 50, minibatch 1000/1000, validation error 48.833004"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 51, minibatch 1000/1000, validation error 48.674651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 52, minibatch 1000/1000, validation error 47.633409"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 53, minibatch 1000/1000, validation error 47.640890"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 54, minibatch 1000/1000, validation error 47.473833"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 55, minibatch 1000/1000, validation error 47.508449"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 56, minibatch 1000/1000, validation error 47.271281"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 57, minibatch 1000/1000, validation error 46.832449"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 58, minibatch 1000/1000, validation error 46.545803"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 59, minibatch 1000/1000, validation error 46.022124"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 60, minibatch 1000/1000, validation error 46.494845"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 61, minibatch 1000/1000, validation error 46.165574"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 62, minibatch 1000/1000, validation error 45.891940"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 63, minibatch 1000/1000, validation error 45.989795"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 64, minibatch 1000/1000, validation error 44.608447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 65, minibatch 1000/1000, validation error 44.342979"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 66, minibatch 1000/1000, validation error 43.411608"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 67, minibatch 1000/1000, validation error 43.566312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 68, minibatch 1000/1000, validation error 43.201194"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 69, minibatch 1000/1000, validation error 43.370429"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 70, minibatch 1000/1000, validation error 43.011550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 71, minibatch 1000/1000, validation error 42.801975"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 72, minibatch 1000/1000, validation error 42.595389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 73, minibatch 1000/1000, validation error 43.260965"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 74, minibatch 1000/1000, validation error 43.034897"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 75, minibatch 1000/1000, validation error 43.525992"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 76, minibatch 1000/1000, validation error 43.387665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 77, minibatch 1000/1000, validation error 43.432409"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 78, minibatch 1000/1000, validation error 43.750308"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 79, minibatch 1000/1000, validation error 43.630736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 80, minibatch 1000/1000, validation error 45.138946"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 81, minibatch 1000/1000, validation error 44.910246"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 82, minibatch 1000/1000, validation error 44.763736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 83, minibatch 1000/1000, validation error 45.669055"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 84, minibatch 1000/1000, validation error 45.790428"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 85, minibatch 1000/1000, validation error 45.075407"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 86, minibatch 1000/1000, validation error 44.930175"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 87, minibatch 1000/1000, validation error 44.300766"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 88, minibatch 1000/1000, validation error 43.815551"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 89, minibatch 1000/1000, validation error 43.893146"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 90, minibatch 1000/1000, validation error 42.917526"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 91, minibatch 1000/1000, validation error 42.090360"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 92, minibatch 1000/1000, validation error 42.816879"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 93, minibatch 1000/1000, validation error 42.244626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 94, minibatch 1000/1000, validation error 41.751757"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 95, minibatch 1000/1000, validation error 42.642385"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 96, minibatch 1000/1000, validation error 41.740146"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 97, minibatch 1000/1000, validation error 41.792247"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 98, minibatch 1000/1000, validation error 41.171874"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 99, minibatch 1000/1000, validation error 41.725803"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "... building the model\n",
        "... training"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 0, minibatch 1000/1000, validation error 811.333748"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 1, minibatch 1000/1000, validation error 537.496177"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2, minibatch 1000/1000, validation error 431.089201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3, minibatch 1000/1000, validation error 363.717784"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4, minibatch 1000/1000, validation error 316.530619"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5, minibatch 1000/1000, validation error 280.451822"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6, minibatch 1000/1000, validation error 253.625917"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7, minibatch 1000/1000, validation error 232.961503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8, minibatch 1000/1000, validation error 216.332629"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9, minibatch 1000/1000, validation error 203.424679"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10, minibatch 1000/1000, validation error 193.005003"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11, minibatch 1000/1000, validation error 184.373655"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12, minibatch 1000/1000, validation error 177.084586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13, minibatch 1000/1000, validation error 170.840618"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14, minibatch 1000/1000, validation error 165.335168"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15, minibatch 1000/1000, validation error 160.410932"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16, minibatch 1000/1000, validation error 155.960665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17, minibatch 1000/1000, validation error 151.909116"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18, minibatch 1000/1000, validation error 148.158444"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19, minibatch 1000/1000, validation error 144.740770"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20, minibatch 1000/1000, validation error 141.485857"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 21, minibatch 1000/1000, validation error 138.429391"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 22, minibatch 1000/1000, validation error 135.565302"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 23, minibatch 1000/1000, validation error 132.837823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 24, minibatch 1000/1000, validation error 130.214137"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 25, minibatch 1000/1000, validation error 127.713622"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 26, minibatch 1000/1000, validation error 125.285768"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 27, minibatch 1000/1000, validation error 122.961500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 28, minibatch 1000/1000, validation error 120.731777"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 29, minibatch 1000/1000, validation error 118.631994"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 30, minibatch 1000/1000, validation error 116.598751"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 31, minibatch 1000/1000, validation error 114.647339"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 32, minibatch 1000/1000, validation error 112.790550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 33, minibatch 1000/1000, validation error 111.021390"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 34, minibatch 1000/1000, validation error 109.327217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 35, minibatch 1000/1000, validation error 107.718037"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 36, minibatch 1000/1000, validation error 106.178240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 37, minibatch 1000/1000, validation error 104.734237"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 38, minibatch 1000/1000, validation error 103.333006"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 39, minibatch 1000/1000, validation error 101.970514"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 40, minibatch 1000/1000, validation error 100.685775"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 41, minibatch 1000/1000, validation error 99.457651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 42, minibatch 1000/1000, validation error 98.263554"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 43, minibatch 1000/1000, validation error 97.144068"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 44, minibatch 1000/1000, validation error 96.074812"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 45, minibatch 1000/1000, validation error 95.061715"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 46, minibatch 1000/1000, validation error 94.091645"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 47, minibatch 1000/1000, validation error 93.148510"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 48, minibatch 1000/1000, validation error 92.236382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 49, minibatch 1000/1000, validation error 91.349532"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 50, minibatch 1000/1000, validation error 90.513804"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 51, minibatch 1000/1000, validation error 89.708560"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 52, minibatch 1000/1000, validation error 88.934383"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 53, minibatch 1000/1000, validation error 88.189369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 54, minibatch 1000/1000, validation error 87.491909"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 55, minibatch 1000/1000, validation error 86.821433"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 56, minibatch 1000/1000, validation error 86.178427"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 57, minibatch 1000/1000, validation error 85.550461"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 58, minibatch 1000/1000, validation error 84.948170"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 59, minibatch 1000/1000, validation error 84.374671"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 60, minibatch 1000/1000, validation error 83.822351"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 61, minibatch 1000/1000, validation error 83.285988"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 62, minibatch 1000/1000, validation error 82.773977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 63, minibatch 1000/1000, validation error 82.290986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 64, minibatch 1000/1000, validation error 81.827342"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 65, minibatch 1000/1000, validation error 81.381492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 66, minibatch 1000/1000, validation error 80.935992"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 67, minibatch 1000/1000, validation error 80.502965"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 68, minibatch 1000/1000, validation error 80.071902"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 69, minibatch 1000/1000, validation error 79.640969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 70, minibatch 1000/1000, validation error 79.232720"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 71, minibatch 1000/1000, validation error 78.809941"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 72, minibatch 1000/1000, validation error 78.406730"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 73, minibatch 1000/1000, validation error 78.020232"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 74, minibatch 1000/1000, validation error 77.655954"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 75, minibatch 1000/1000, validation error 77.303908"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 76, minibatch 1000/1000, validation error 76.970356"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 77, minibatch 1000/1000, validation error 76.636089"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 78, minibatch 1000/1000, validation error 76.310085"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 79, minibatch 1000/1000, validation error 75.994890"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 80, minibatch 1000/1000, validation error 75.685647"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 81, minibatch 1000/1000, validation error 75.382989"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 82, minibatch 1000/1000, validation error 75.098856"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 83, minibatch 1000/1000, validation error 74.815875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 84, minibatch 1000/1000, validation error 74.539432"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 85, minibatch 1000/1000, validation error 74.274937"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 86, minibatch 1000/1000, validation error 74.015454"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 87, minibatch 1000/1000, validation error 73.759666"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 88, minibatch 1000/1000, validation error 73.505077"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 89, minibatch 1000/1000, validation error 73.257657"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 90, minibatch 1000/1000, validation error 73.015961"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 91, minibatch 1000/1000, validation error 72.779014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 92, minibatch 1000/1000, validation error 72.548349"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 93, minibatch 1000/1000, validation error 72.320784"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 94, minibatch 1000/1000, validation error 72.093098"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 95, minibatch 1000/1000, validation error 71.867071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 96, minibatch 1000/1000, validation error 71.644548"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 97, minibatch 1000/1000, validation error 71.427277"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 98, minibatch 1000/1000, validation error 71.213832"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 99, minibatch 1000/1000, validation error 71.003274"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def posterior_mean():\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rv, s, _ = valid_data_1\n",
      "s=s.T*90\n",
      "opt_preds = fit_optimal(rv, sm, s)\n",
      "mse_opt = np.mean((opt_preds[0] - s[0]) ** 2 + (opt_preds[1] - s[1]) ** 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "#plt.plot(range(20, 100), valid_mse_plain[20:100], c='b')\n",
      "#plt.plot(range(20, 100), valid_mse_rms[20:100], c='y')\n",
      "plt.plot(valid_mse_plain, c='b', label='Vanilla')\n",
      "plt.plot(valid_mse_rms, c='k', label='RMSProp')\n",
      "plt.plot(np.ones(100) * mse_opt, c='r', label='MAP')\n",
      "plt.legend()\n",
      "plt.xlabel('epoch')\n",
      "plt.ylabel('MSE')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = -30\n",
      "num_deltas = 60\n",
      "#num_deltas = 5\n",
      "\n",
      "mean_s1_nn_rms = [None] * num_deltas\n",
      "mean_s2_nn_rms = [None] * num_deltas\n",
      "bias_s1_nn_rms = [None] * num_deltas\n",
      "bias_s2_nn_rms = [None] * num_deltas\n",
      "var_s1_nn_rms = [None] * num_deltas\n",
      "var_s2_nn_rms = [None] * num_deltas\n",
      "corr_nn_rms = [None] * num_deltas\n",
      "cov_nn_rms = [None] * num_deltas\n",
      "\n",
      "\"\"\"\n",
      "mean_s1_nn_rms_m9 = [None] * num_deltas\n",
      "mean_s2_nn_rms_m9 = [None] * num_deltas\n",
      "bias_s1_nn_rms_m9 = [None] * num_deltas\n",
      "bias_s2_nn_rms_m9 = [None] * num_deltas\n",
      "var_s1_nn_rms_m9 = [None] * num_deltas\n",
      "var_s2_nn_rms_m9 = [None] * num_deltas\n",
      "corr_nn_rms_m9 = [None] * num_deltas\n",
      "cov_nn_rms_m9 = [None] * num_deltas\n",
      "\n",
      "mean_s1_nn_rms_m9f = [None] * num_deltas\n",
      "mean_s2_nn_rms_m9f = [None] * num_deltas\n",
      "bias_s1_nn_rms_m9f = [None] * num_deltas\n",
      "bias_s2_nn_rms_m9f = [None] * num_deltas\n",
      "var_s1_nn_rms_m9f = [None] * num_deltas\n",
      "var_s2_nn_rms_m9f = [None] * num_deltas\n",
      "corr_nn_rms_m9f = [None] * num_deltas\n",
      "cov_nn_rms_m9f = [None] * num_deltas\n",
      "\n",
      "mean_s1_nn_rms_m95 = [None] * num_deltas\n",
      "mean_s2_nn_rms_m95 = [None] * num_deltas\n",
      "bias_s1_nn_rms_m95 = [None] * num_deltas\n",
      "bias_s2_nn_rms_m95 = [None] * num_deltas\n",
      "var_s1_nn_rms_m95 = [None] * num_deltas\n",
      "var_s2_nn_rms_m95 = [None] * num_deltas\n",
      "corr_nn_rms_m95 = [None] * num_deltas\n",
      "cov_nn_rms_m95 = [None] * num_deltas\n",
      "\n",
      "mean_s1_nn_rms_m99 = [None] * num_deltas\n",
      "mean_s2_nn_rms_m99 = [None] * num_deltas\n",
      "bias_s1_nn_rms_m99 = [None] * num_deltas\n",
      "bias_s2_nn_rms_m99 = [None] * num_deltas\n",
      "var_s1_nn_rms_m99 = [None] * num_deltas\n",
      "var_s2_nn_rms_m99 = [None] * num_deltas\n",
      "corr_nn_rms_m99 = [None] * num_deltas\n",
      "cov_nn_rms_m99 = [None] * num_deltas\n",
      "\n",
      "mean_s1_nn_plain = [None] * num_deltas\n",
      "mean_s2_nn_plain = [None] * num_deltas\n",
      "bias_s1_nn_plain = [None] * num_deltas\n",
      "bias_s2_nn_plain = [None] * num_deltas\n",
      "var_s1_nn_plain = [None] * num_deltas\n",
      "var_s2_nn_plain = [None] * num_deltas\n",
      "corr_nn_plain = [None] * num_deltas\n",
      "cov_nn_plain = [None] * num_deltas\n",
      "\"\"\"\n",
      "\n",
      "mean_s1_opt = [None] * num_deltas\n",
      "mean_s2_opt = [None] * num_deltas\n",
      "bias_s1_opt = [None] * num_deltas\n",
      "bias_s2_opt = [None] * num_deltas\n",
      "var_s1_opt = [None] * num_deltas\n",
      "var_s2_opt = [None] * num_deltas\n",
      "corr_opt = [None] * num_deltas\n",
      "cov_opt = [None] * num_deltas\n",
      "\n",
      "var_s1_fisher = [None] * num_deltas\n",
      "var_s2_fisher = [None] * num_deltas\n",
      "cov_fisher = [None] * num_deltas\n",
      "\n",
      "for delta_s in range(num_deltas):\n",
      "    #test_data = generate_s_data(s1, s1 + delta_s + 1, 3000)\n",
      "    test_data = generate_s_data(s1, s1 + delta_s, 300)\n",
      "    nn_preds_rms, _ = test_nn(nn_rms, nnx_rms, test_data)\n",
      "    \"\"\"\n",
      "    nn_preds_rms_m9, _ = test_nn(nn_rms_m9, nnx_rms_m9, test_data)\n",
      "    nn_preds_rms_m9f, _ = test_nn(nn_rms_m9f, nnx_rms_m9f, test_data)\n",
      "    nn_preds_rms_m95, _ = test_nn(nn_rms_m95, nnx_rms_m95, test_data)\n",
      "    nn_preds_rms_m99, _ = test_nn(nn_rms_m99, nnx_rms_m99, test_data)\n",
      "    nn_preds_plain, _ = test_nn(nn_plain, nnx_plain, test_data)\n",
      "    \"\"\"\n",
      "    r, _, _ = test_data\n",
      "    opt_preds = fit_optimal(r, sm, init={'s_1':s1, 's_2':s1 + delta_s + 1})\n",
      "    \n",
      "    nn_preds_rms = nn_preds_rms.T * 90\n",
      "    \"\"\"\n",
      "    nn_preds_rms_m9 = nn_preds_rms_m9.T * 90\n",
      "    nn_preds_rms_m9f = nn_preds_rms_m9f.T * 90\n",
      "    nn_preds_rms_m95 = nn_preds_rms_m95.T * 90\n",
      "    nn_preds_rms_m99 = nn_preds_rms_m99.T * 90\n",
      "    nn_preds_plain = nn_preds_plain.T * 90\n",
      "    \"\"\"\n",
      "\n",
      "    nn_stats_rms = get_statistics(s1, s1 + delta_s, nn_preds_rms)\n",
      "    \"\"\"\n",
      "    nn_stats_rms_m9 = get_statistics(s1, s1 + delta_s, nn_preds_rms_m9)\n",
      "    nn_stats_rms_m9f = get_statistics(s1, s1 + delta_s, nn_preds_rms_m9f)\n",
      "    nn_stats_rms_m95 = get_statistics(s1, s1 + delta_s, nn_preds_rms_m95)\n",
      "    nn_stats_rms_m99 = get_statistics(s1, s1 + delta_s, nn_preds_rms_m99)\n",
      "    nn_stats_plain = get_statistics(s1, s1 + delta_s, nn_preds_plain)\n",
      "    \"\"\"\n",
      "    opt_stats = get_statistics(s1, s1 + delta_s, opt_preds)\n",
      "    \n",
      "    if delta_s > 0:\n",
      "        FI = fisher_inf(s1, s1 + delta_s, .5, .5)\n",
      "        var_s1_fisher[delta_s] = FI[0, 0]\n",
      "        var_s2_fisher[delta_s] = FI[1, 1]\n",
      "        cov_fisher[delta_s] = FI[0, 1]\n",
      "    \n",
      "    mean_s1_nn_rms[delta_s] = nn_stats_rms['mean_s1']\n",
      "    mean_s2_nn_rms[delta_s] = nn_stats_rms['mean_s2']\n",
      "    bias_s1_nn_rms[delta_s] = nn_stats_rms['bias_s1']\n",
      "    bias_s2_nn_rms[delta_s] = nn_stats_rms['bias_s2']\n",
      "    var_s1_nn_rms[delta_s] = nn_stats_rms['var_s1']\n",
      "    var_s2_nn_rms[delta_s] = nn_stats_rms['var_s2']\n",
      "    corr_nn_rms[delta_s] = nn_stats_rms['corr']\n",
      "    cov_nn_rms[delta_s] = nn_stats_rms['cov']\n",
      "    \n",
      "    mean_s1_opt[delta_s] = opt_stats['mean_s1']\n",
      "    mean_s2_opt[delta_s] = opt_stats['mean_s2']\n",
      "    bias_s1_opt[delta_s] = opt_stats['bias_s1']\n",
      "    bias_s2_opt[delta_s] = opt_stats['bias_s2']\n",
      "    var_s1_opt[delta_s] = opt_stats['var_s1']\n",
      "    var_s2_opt[delta_s] = opt_stats['var_s2']\n",
      "    corr_opt[delta_s] = opt_stats['corr']\n",
      "    cov_opt[delta_s] = opt_stats['cov']\n",
      "    \n",
      "    \"\"\"\n",
      "    mean_s1_nn_rms_m9[delta_s] = nn_stats_rms_m9['mean_s1']\n",
      "    mean_s2_nn_rms_m9[delta_s] = nn_stats_rms_m9['mean_s2']\n",
      "    bias_s1_nn_rms_m9[delta_s] = nn_stats_rms_m9['bias_s1']\n",
      "    bias_s2_nn_rms_m9[delta_s] = nn_stats_rms_m9['bias_s2']\n",
      "    var_s1_nn_rms_m9[delta_s] = nn_stats_rms_m9['var_s1']\n",
      "    var_s2_nn_rms_m9[delta_s] = nn_stats_rms_m9['var_s2']\n",
      "    corr_nn_rms_m9[delta_s] = nn_stats_rms_m9['corr']\n",
      "    cov_nn_rms_m9[delta_s] = nn_stats_rms_m9['cov']\n",
      "    \n",
      "    mean_s1_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['mean_s1']\n",
      "    mean_s2_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['mean_s2']\n",
      "    bias_s1_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['bias_s1']\n",
      "    bias_s2_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['bias_s2']\n",
      "    var_s1_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['var_s1']\n",
      "    var_s2_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['var_s2']\n",
      "    corr_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['corr']\n",
      "    cov_nn_rms_m9f[delta_s] = nn_stats_rms_m9f['cov']\n",
      "    \n",
      "    mean_s1_nn_rms_m95[delta_s] = nn_stats_rms_m95['mean_s1']\n",
      "    mean_s2_nn_rms_m95[delta_s] = nn_stats_rms_m95['mean_s2']\n",
      "    bias_s1_nn_rms_m95[delta_s] = nn_stats_rms_m95['bias_s1']\n",
      "    bias_s2_nn_rms_m95[delta_s] = nn_stats_rms_m95['bias_s2']\n",
      "    var_s1_nn_rms_m95[delta_s] = nn_stats_rms_m95['var_s1']\n",
      "    var_s2_nn_rms_m95[delta_s] = nn_stats_rms_m95['var_s2']\n",
      "    corr_nn_rms_m95[delta_s] = nn_stats_rms_m95['corr']\n",
      "    cov_nn_rms_m95[delta_s] = nn_stats_rms_m95['cov']\n",
      "    \n",
      "    mean_s1_nn_rms_m99[delta_s] = nn_stats_rms_m99['mean_s1']\n",
      "    mean_s2_nn_rms_m99[delta_s] = nn_stats_rms_m99['mean_s2']\n",
      "    bias_s1_nn_rms_m99[delta_s] = nn_stats_rms_m99['bias_s1']\n",
      "    bias_s2_nn_rms_m99[delta_s] = nn_stats_rms_m99['bias_s2']\n",
      "    var_s1_nn_rms_m99[delta_s] = nn_stats_rms_m99['var_s1']\n",
      "    var_s2_nn_rms_m99[delta_s] = nn_stats_rms_m99['var_s2']\n",
      "    corr_nn_rms_m99[delta_s] = nn_stats_rms_m99['corr']\n",
      "    cov_nn_rms_m99[delta_s] = nn_stats_rms_m99['cov']\n",
      "    \n",
      "    mean_s1_nn_plain[delta_s] = nn_stats_plain['mean_s1']\n",
      "    mean_s2_nn_plain[delta_s] = nn_stats_plain['mean_s2']\n",
      "    bias_s1_nn_plain[delta_s] = nn_stats_plain['bias_s1']\n",
      "    bias_s2_nn_plain[delta_s] = nn_stats_plain['bias_s2']\n",
      "    var_s1_nn_plain[delta_s] = nn_stats_plain['var_s1']\n",
      "    var_s2_nn_plain[delta_s] = nn_stats_plain['var_s2']\n",
      "    corr_nn_plain[delta_s] = nn_stats_plain['corr']\n",
      "    cov_nn_plain[delta_s] = nn_stats_plain['cov']\n",
      "    \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.patches as mpatches\n",
      "s = range(-30, 30)\n",
      "neg_sd_nn_rms = mean_s1_nn_rms - np.sqrt(var_s1_nn_rms)\n",
      "pos_sd_nn_rms = mean_s1_nn_rms + np.sqrt(var_s1_nn_rms)\n",
      "neg_sd_opt = mean_s1_opt - np.sqrt(var_s1_opt)\n",
      "pos_sd_opt = mean_s1_opt + np.sqrt(var_s1_opt)\n",
      "plt.rc('text', usetex=True)\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.fill_between(s, pos_sd_nn_rms, neg_sd_nn_rms, facecolor='k', alpha=0.5, edgecolor=\"None\", label=\"MLE\")\n",
      "plt.fill_between(s, pos_sd_opt, neg_sd_opt, facecolor='m', alpha=0.5, edgecolor=\"None\", label=\"NN\")\n",
      "plt.ylim([-40,40])\n",
      "plt.xlabel(r'$s_2$',fontsize=30)\n",
      "plt.ylabel(r'\\hat{s_1}',fontsize=30)\n",
      "nn_patch = mpatches.Patch(color='k', label='NN')\n",
      "mle_patch = mpatches.Patch(color='m', label='MLE')\n",
      "plt.legend(handles=[nn_patch, mle_patch])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = range(-30, 30)\n",
      "neg_sd_nn_rms = mean_s2_nn_rms - np.sqrt(var_s2_nn_rms)\n",
      "pos_sd_nn_rms = mean_s2_nn_rms + np.sqrt(var_s2_nn_rms)\n",
      "neg_sd_opt = mean_s2_opt - np.sqrt(var_s2_opt)\n",
      "pos_sd_opt = mean_s2_opt + np.sqrt(var_s2_opt)\n",
      "plt.rc('text', usetex=True)\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.fill_between(s, pos_sd_nn_rms, neg_sd_nn_rms, facecolor='k', alpha=0.5, edgecolor=\"None\")\n",
      "plt.fill_between(s, pos_sd_opt, neg_sd_opt, facecolor='m', alpha=0.5, edgecolor=\"None\")\n",
      "plt.xlabel(r'$s_2$',fontsize=30)\n",
      "plt.ylabel(r'\\hat{s_2}',fontsize=30)\n",
      "plt.ylim([-40,40])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5)\n",
      "#RMS\n",
      "ax1.plot(range(1, 61), bias_s1_nn_rms, c='k', label='NN')\n",
      "ax2.plot(range(1, 61), bias_s2_nn_rms, c='k', label='NN')\n",
      "ax3.plot(range(1, 61), var_s1_nn_rms, c='k', label='NN')\n",
      "ax4.plot(range(1, 61), var_s2_nn_rms, c='k', label='NN')\n",
      "ax5.plot(range(1, 61), cov_nn_rms, c='k', label='NN')\n",
      "#optimal in red\n",
      "ax1.plot(range(1, 61), bias_s1_opt, c='m', label='MLE')\n",
      "ax2.plot(range(1, 61), bias_s2_opt, c='m', label='MLE')\n",
      "ax3.plot(range(1, 61), var_s1_opt, c='m', label='MLE')\n",
      "ax4.plot(range(1, 61), var_s2_opt, c='m', label='MLE')\n",
      "ax5.plot(range(1, 61), cov_opt, c='m', label='MLE')\n",
      "\"\"\"\n",
      "#RMS with momentum\n",
      "ax1.plot(range(1, 61), bias_s1_nn_rms_m9, c='m', label='NN')\n",
      "ax2.plot(range(1, 61), bias_s2_nn_rms_m9, c='m', label='NN')\n",
      "ax3.plot(range(1, 61), var_s1_nn_rms_m9, c='m', label='NN')\n",
      "ax4.plot(range(1, 61), var_s2_nn_rms_m9, c='m', label='NN')\n",
      "ax5.plot(range(1, 61), cov_nn_rms_m9, c='m', label='NN')\n",
      "#RMS with momentum\n",
      "ax1.plot(range(1, 61), bias_s1_nn_rms_m95, c='c', label='NN')\n",
      "ax2.plot(range(1, 61), bias_s2_nn_rms_m95, c='c', label='NN')\n",
      "ax3.plot(range(1, 61), var_s1_nn_rms_m95, c='c', label='NN')\n",
      "ax4.plot(range(1, 61), var_s2_nn_rms_m95, c='c', label='NN')\n",
      "ax5.plot(range(1, 61), cov_nn_rms_m95, c='c', label='NN')\n",
      "#RMS with momentum\n",
      "ax1.plot(range(1, 61), bias_s1_nn_rms_m99, c='k', label='NN')\n",
      "ax2.plot(range(1, 61), bias_s2_nn_rms_m99, c='k', label='NN')\n",
      "ax3.plot(range(1, 61), var_s1_nn_rms_m99, c='k', label='NN')\n",
      "ax4.plot(range(1, 61), var_s2_nn_rms_m99, c='k', label='NN')\n",
      "ax5.plot(range(1, 61), cov_nn_rms_m99, c='k', label='NN')\n",
      "#RMS\n",
      "ax1.plot(range(1, 61), bias_s1_nn_rms_m9f, c='r', label='NN')\n",
      "ax2.plot(range(1, 61), bias_s2_nn_rms_m9f, c='r', label='NN')\n",
      "ax3.plot(range(1, 61), var_s1_nn_rms_m9f, c='r', label='NN')\n",
      "ax4.plot(range(1, 61), var_s2_nn_rms_m9f, c='r', label='NN')\n",
      "ax5.plot(range(1, 61), cov_nn_rms_m9f, c='r', label='NN')\n",
      "#Plain\n",
      "ax1.plot(range(1, 61), bias_s1_nn_plain, c='b', label='NN')\n",
      "ax2.plot(range(1, 61), bias_s2_nn_plain, c='b', label='NN')\n",
      "ax3.plot(range(1, 61), var_s1_nn_plain, c='b', label='NN')\n",
      "ax4.plot(range(1, 61), var_s2_nn_plain, c='b', label='NN')\n",
      "ax5.plot(range(1, 61), cov_nn_plain, c='b', label='NN')\n",
      "\"\"\"\n",
      "#Fisher information in green\n",
      "ax3.plot(range(7, 61), var_s1_fisher[6:60], c='orange', label='Fisher')\n",
      "ax4.plot(range(7, 61), var_s2_fisher[6:60], c='orange', label='Fisher')\n",
      "ax5.plot(range(7, 61), cov_fisher[6:60], c='orange', label='Fisher')\n",
      "ax1.locator_params(axis = 'y', nbins = 4)\n",
      "ax2.locator_params(axis = 'y', nbins = 4)\n",
      "ax3.locator_params(axis = 'y', nbins = 4)\n",
      "ax4.locator_params(axis = 'y', nbins = 4)\n",
      "ax5.locator_params(axis = 'y', nbins = 4)\n",
      "#ax1.legend()\n",
      "ax1.set_title(\"Bias $s_1$\")\n",
      "ax2.set_title(\"Bias $s_2$\")\n",
      "ax3.set_title(r'Variance $s_1$')\n",
      "ax4.set_title(r'Variance $s_2$')\n",
      "ax5.set_title('Covariance')\n",
      "ax5.set_xlabel(r'$\\Delta$ s')\n",
      "f.set_size_inches(10,10)\n",
      "ax3.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}