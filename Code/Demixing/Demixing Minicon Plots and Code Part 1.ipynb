{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Describe training. Different ways of training, generalization across gains. Bias and variance as a function of Delta s and gains (think abpout how to plot smartly, to avoid having too many plots)\n",
    "    \n",
    "Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.patches as mpatches\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "nneuron = 61\n",
    "min_angle = -90\n",
    "max_angle = 90\n",
    "sprefs = np.linspace(min_angle, max_angle, nneuron)\n",
    "eps = np.finfo(np.float64).eps\n",
    "sigtc_sq = float(10**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    shape = (len(x) for x in arrays)\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    ix = np.indices(shape)\n",
    "    ix = ix.reshape(len(arrays), -1).T\n",
    "\n",
    "    if out is None:\n",
    "        out = np.empty_like(ix, dtype=dtype)\n",
    "\n",
    "    for n, arr in enumerate(arrays):\n",
    "        out[:, n] = arrays[n][ix[:, n]]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_s(ndata, sort):\n",
    "    s = np.random.rand(2, ndata) * 120 - 60\n",
    "    if sort:\n",
    "        s = np.sort(s, axis=0)\n",
    "    return s[0], s[1]\n",
    "\n",
    "def random_c(ndata, ndims, low, high, sort):\n",
    "    c_range = high - low\n",
    "    if ndims == 1:\n",
    "        c = np.random.rand(ndims, ndata)[0] * c_range + low\n",
    "    else:\n",
    "        c = np.random.rand(ndims, ndata) * c_range + low\n",
    "    if sort:\n",
    "        c = np.sort(c, axis=0)\n",
    "    return c\n",
    "    \n",
    "def generate_popcode_data(ndata, nneuron, sigtc_sq, r_max, noise, sort, s_0, s_1, c_0, c_1, c_50=13.1):\n",
    "    c_rms = np.sqrt(np.square(c_0) + np.square(c_1))\n",
    "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
    "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_0 = c_0 * s_0t.T\n",
    "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_1 = c_1 * s_1t.T\n",
    "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
    "    r = r_max * (stim_0 + stim_1)\n",
    "    r = r.T\n",
    "    s = np.array((s_0, s_1)).T\n",
    "    s = s/90\n",
    "    c = np.array((c_0, c_1)).T\n",
    "    if noise == \"poisson\":\n",
    "        r = np.random.poisson(r) + 0.0\n",
    "    return r, s, c\n",
    "\n",
    "def generate_trainset(ndata, highlow=False, discrete_c=None, low=.3, high=.7, r_max=10):\n",
    "    s_0, s_1 = random_s(ndata, True)\n",
    "    if highlow:\n",
    "        c_0, c_1 = np.concatenate((np.ones((2, ndata/2)) * low, np.ones((2, ndata/2)) * high), axis=1)\n",
    "    elif discrete_c:\n",
    "        cs = np.linspace(low, high, discrete_c)\n",
    "        perm_cs = cartesian((cs, cs))\n",
    "        c_arr = np.repeat(perm_cs, ndata/(discrete_c**2), axis=0)\n",
    "        np.random.shuffle(c_arr)\n",
    "        c_0, c_1 = c_arr.T\n",
    "        print ndata/(discrete_c**2), \"trials per contrast level\"\n",
    "        if ndata%(discrete_c**2) != 0:\n",
    "            print \"Not divisible, only generated\", ndata / (discrete_c**2) * (discrete_c**2), \"trials\"\n",
    "        ndata = ndata / (discrete_c**2) * (discrete_c**2)\n",
    "    else:\n",
    "        c_0, c_1 = np.ones((2, ndata)) * .5\n",
    "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
    "    return r, s, c\n",
    "\n",
    "def generate_testset(ndata, stim_0=None, stim_1=None, con_0=None, con_1=None, discrete_c=None, low=.5, high=.5, r_max=10):\n",
    "    if con_0:\n",
    "        c_0 = np.ones(ndata) * con_0\n",
    "        c_1 = np.ones(ndata) * con_1\n",
    "    else:\n",
    "        c_range = high - low\n",
    "        if discrete_c:\n",
    "            cs = np.linspace(low, high, discrete_c)\n",
    "            perm_cs = cartesian((cs, cs))\n",
    "            c_0, c_1 = np.repeat(perm_cs, ndata/(discrete_c**2), axis=0).T\n",
    "            print ndata/(discrete_c**2), \"trials per contrast level\"\n",
    "            if ndata%(discrete_c**2) != 0:\n",
    "                print \"Not divisible, only generated\", ndata / (discrete_c**2) * (discrete_c**2), \"trials\"\n",
    "            ndata = ndata / (discrete_c**2) * (discrete_c**2)\n",
    "        else:\n",
    "            c_0, c_1 = np.random.rand(2, ndata) * c_range + low\n",
    "    if not stim_0:\n",
    "        s_0, s_1 = random_s(ndata, True)\n",
    "    else:\n",
    "        s_0, s_1 = np.ones((2, ndata))\n",
    "        s_0 = s_0 * stim_0\n",
    "        s_1 = s_1 * stim_1\n",
    "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
    "    return r, s, c\n",
    "\n",
    "def generate_trainset_cat(ndata, low=.3, high=1.3, crange=.5, r_max=10):\n",
    "    numvec = np.random.binomial(1, .5, size=ndata).astype(int)\n",
    "    c_0 = random_c(ndata, 1, high, high+crange, True)\n",
    "    c_1 = random_c(ndata, 1, low, low+crange, True)\n",
    "    s_0, s_1 = np.random.rand(2, ndata) * 120 - 60\n",
    "    r, numvec, s, c  = generate_popcode_data_cat(ndata, numvec, nneuron, sigtc_sq, c_50, r_max, \"poisson\", s_0, s_1, c_0, c_1)\n",
    "    y = s[range(ndata), numvec]\n",
    "    return r, y, s, c, numvec \n",
    "    \n",
    "def generate_popcode_data_cat(ndata, numvec, nneuron, sigtc_sq, c_50, r_max, noise, s_0, s_1, c_0, c_1):\n",
    "    c0vec = c_0 * np.ones(ndata)\n",
    "    c1vec = c_1 * numvec\n",
    "    c_rms = np.sqrt(np.square(c0vec) + np.square(c1vec))\n",
    "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
    "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_0 = c0vec * s_0t.T\n",
    "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_1 = c1vec * s_1t.T\n",
    "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
    "    r = r_max * (stim_0 + stim_1)/(c_rms)\n",
    "    #r = r_max * (stim_0 + stim_1)\n",
    "    r = r.T\n",
    "    s = np.array((s_0, s_1)).T\n",
    "    s = s/90\n",
    "    c = np.array((c_0, c_1)).T\n",
    "    if noise == \"poisson\":\n",
    "        r = np.random.poisson(r) + 0.0\n",
    "    return r, numvec, s, c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lik_means(s_1, s_2, c_0=.5, c_1=.5, sprefs=sprefs, sigtc_sq=sigtc_sq, r_max=10):\n",
    "    sprefs_data = np.tile(sprefs, (len(s_1), 1))\n",
    "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_0 = c_0 * s_0t.T\n",
    "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_2, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_1 = c_1 * s_1t.T\n",
    "    r = r_max * (stim_0 + stim_1)\n",
    "    return r.T\n",
    "def posterior(r, means, s1_grid, s2_grid):\n",
    "    ns_liks = poisson.pmf(r, mu=means)\n",
    "    stim_liks = np.prod(ns_liks, axis=1)\n",
    "    #p_s = 2/14400\n",
    "    #logp_s = np.log(p_s)\n",
    "    logp_s = -3.8573325\n",
    "    loglik = np.sum(np.log(ns_liks), axis=1)\n",
    "    mean1 = np.sum(s1_grid * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    mean2 = np.sum(s2_grid * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    expsquare1 = np.sum(np.square(s1_grid) * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    expsquare2 = np.sum(np.square(s2_grid) * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    var1 = expsquare1 - np.square(mean1)\n",
    "    var2 = expsquare2 - np.square(mean2)\n",
    "    return mean1, mean2, var1, var2\n",
    "def posterior_setup(low=.3, high=.7, discrete_c = 3, num_s=100, r_max=10):\n",
    "    grid = np.linspace(-60, 60, num_s)\n",
    "    s1s = np.concatenate([[grid[i]]*(num_s-i) for i in range(num_s)])\n",
    "    cs = np.linspace(low, high, discrete_c)\n",
    "    s1_grid, c1_grid, c2_grid = cartesian((s1s, cs, cs)).T\n",
    "    s2s = np.concatenate([grid[i:num_s+1] for i in range(num_s)])\n",
    "    s2_grid = np.repeat(s2s, (discrete_c**2), axis=0)\n",
    "    means = lik_means(s1_grid, s2_grid, c_0=c1_grid, c_1=c2_grid, r_max=r_max)\n",
    "    partial_post = partial(posterior, means=means, s1_grid=s1_grid, s2_grid=s2_grid)\n",
    "    return partial_post\n",
    "def get_posteriors(r, post_func):\n",
    "    posteriors = {'mean_s1': None, 'mean_s2': None, 'var_s1': None, 'var_s2': None}\n",
    "    p = np.array([post_func(r[i]) for i in range(len(r))]).T\n",
    "    posteriors['mean_s1'], posteriors['mean_s2'], posteriors['var_s1'], posteriors['var_s2'] = p\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multilayer ReLU net\n",
    "\"\"\"\n",
    "\n",
    "def relu(x):\n",
    "    return theano.tensor.switch(x<0, 0, x)\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out, W=None, b=None,\n",
    "                 activation=T.nnet.sigmoid):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        :type rng: np.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.dmatrix\n",
    "        :param input: a symbolic tensor of shape (n_examples, n_in)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: theano.Op or function\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        if W is None:\n",
    "            W_values = (1/np.sqrt(n_in)) * np.random.randn(n_in, n_out)\n",
    "            \n",
    "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
    "\n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        lin_output = T.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if activation is None\n",
    "            else activation(lin_output)\n",
    "        )\n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "class MLP(object):\n",
    "\n",
    "\n",
    "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
    "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
    "\n",
    "        :type rng: np.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "        architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "        which the datapoints lie\n",
    "\n",
    "        :type n_hidden: int\n",
    "        :param n_hidden: number of hidden units\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "        which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.hiddenLayer1 = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=input,\n",
    "            n_in=n_in,\n",
    "            n_out=n_hidden,\n",
    "            #activation=T.nnet.sigmoid\n",
    "            activation=relu\n",
    "        )\n",
    "        \n",
    "        self.hiddenLayer2 = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=self.hiddenLayer1.output,\n",
    "            n_in=n_hidden,\n",
    "            n_out=n_out,\n",
    "            #activation=relu\n",
    "            activation=None\n",
    "        )\n",
    "        \n",
    "        self.y_pred = self.hiddenLayer2.output\n",
    "        \n",
    "        # the parameters of the model are the parameters of the two layers it is made out of\n",
    "        self.params = self.hiddenLayer1.params + self.hiddenLayer2.params\n",
    "    \n",
    "    def get_params(self):\n",
    "\n",
    "        params = {}\n",
    "        for param in self.params:\n",
    "            name = param.name\n",
    "            if name in params:\n",
    "                name = name, 2\n",
    "            params[name] = param.get_value()\n",
    "        return params\n",
    "    \n",
    "    def mse(self, y):\n",
    "        # error between output and target\n",
    "        if y.ndim == 1:\n",
    "            se = (self.y_pred.T - y)**2\n",
    "        else:\n",
    "            se = T.sum((self.y_pred - y)**2, axis=1)\n",
    "        return T.mean(se)\n",
    "        \n",
    "    \n",
    "    def valid_mse(self, y):\n",
    "        if y.ndim == 1:\n",
    "            se = (self.y_pred.T * 90 - y * 90)**2\n",
    "        else:\n",
    "            se = T.sum((self.y_pred * 90 - y * 90)**2, axis=1)\n",
    "        return T.mean(se)\n",
    "\n",
    "    \n",
    "class Perceptron(object):\n",
    "\n",
    "\n",
    "    def __init__(self, rng, input, n_in, n_out):\n",
    "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
    "\n",
    "        :type rng: np.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "        architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "        which the datapoints lie\n",
    "\n",
    "        :type n_hidden: int\n",
    "        :param n_hidden: number of hidden units\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "        which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.layer = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=input,\n",
    "            n_in=n_in,\n",
    "            n_out=n_out,\n",
    "            #activation=T.nnet.sigmoid\n",
    "            activation=relu\n",
    "        )\n",
    "        \n",
    "        self.y_pred = self.layer.output\n",
    "        \n",
    "        # the parameters of the model are the parameters of the two layers it is made out of\n",
    "        self.params = self.layer.params\n",
    "        \n",
    "    def get_params(self):\n",
    "\n",
    "        params = {}\n",
    "        for param in self.params:\n",
    "            name = param.name\n",
    "            if name in params:\n",
    "                name = name, 2\n",
    "            params[name] = param.get_value()\n",
    "        return params\n",
    "    \n",
    "    def mse(self, y):\n",
    "        # error between output and target\n",
    "        if y.ndim == 1:\n",
    "            se = (self.y_pred.T - y)**2\n",
    "        else:\n",
    "            se = T.sum((self.y_pred - y)**2, axis=1)\n",
    "        return T.mean(se)\n",
    "    \n",
    "    def valid_mse(self, y):\n",
    "        return mse(self, y)\n",
    "        \n",
    "\n",
    "def shared_dataset(data_xy, borrow=True, no_c=False):\n",
    "        \"\"\" Function that loads the dataset into shared variables\n",
    "        \"\"\"\n",
    "        data_x, data_y = data_xy[:2]\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                               dtype='float32'),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(np.asarray(data_y,\n",
    "                                               dtype='float32'),\n",
    "                                 borrow=borrow)\n",
    "        return shared_x, shared_y\n",
    "\n",
    "def train_nn(train_dataset, valid_dataset=None, n_hidden=20, learning_rate=0.01, n_epochs=10, batch_size=20, linear=False, mult_ys=True, rho=0, nesterov=True, mu=0, n_in=61, n_out=2):\n",
    "    \"\"\"\n",
    "    Demonstrate stochastic gradient descent optimization for a multilayer\n",
    "    perceptron\n",
    "\n",
    "    :type learning_rate: float\n",
    "    :param learning_rate: learning rate used (factor for the stochastic\n",
    "    gradient\n",
    "\n",
    "    :type n_epochs: int\n",
    "    :param n_epochs: maximal number of epochs to run the optimizer\n",
    "\n",
    "   \"\"\"\n",
    "    train_set_x, train_set_y = shared_dataset(train_dataset)\n",
    "    if valid_dataset:\n",
    "        valid_set_x, valid_set_y = shared_dataset(valid_dataset)\n",
    "    \n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    # BUILD ACTUAL MODEL #\n",
    "    ######################\n",
    "    print '... building the model'\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "    x = T.fmatrix('x')   # input data from visual neurons\n",
    "    if n_out == 1:\n",
    "        y = T.fvector('y') # ground truth\n",
    "    else:\n",
    "        y = T.fmatrix('y')  # ground truth\n",
    "\n",
    "    rng = np.random.RandomState(1234)\n",
    "\n",
    "    # construct the MLP class\n",
    "    if linear:\n",
    "        nn = Perceptron(rng=rng, input=x, n_in=n_in, n_out=n_out)\n",
    "    else:\n",
    "        nn = MLP(rng=rng, input=x, n_in=n_in, n_hidden=n_hidden, n_out=n_out)\n",
    "    \n",
    "    cost = nn.mse(y)\n",
    "    \n",
    "    def RMSprop(cost, params, learning_rate=0.001, rho=0.9, epsilon=1e-6, mu=0, nesterov=False):\n",
    "        gparams = T.grad(cost, params)\n",
    "        updates = []\n",
    "        for p, g in zip(params, gparams):\n",
    "            v = theano.shared(p.get_value() * 0.)\n",
    "            ms = theano.shared(p.get_value() * 0.)\n",
    "            ms_new = rho * ms + (1 - rho) * g ** 2\n",
    "            gradient_scaling = T.sqrt(ms_new + epsilon)\n",
    "            g = g / gradient_scaling\n",
    "            \"\"\"\n",
    "            (1) v_t = mu * v_t-1 - lr * gradient_f(params_t)\n",
    "            or\n",
    "            classic\n",
    "            (2) params_t = params_t-1 + v_t\n",
    "            nesterov\n",
    "            (7) params_t = params_t-1 + mu * v_t - lr * gradient_f(params_t-1)\n",
    "            (8) params_t = params_t-1 + mu**2 * v_t-1 - (1+mu) * lr * gradient_f(params_t-1)\n",
    "            \"\"\"\n",
    "            v_new = mu * v - (1 - mu) * learning_rate * g\n",
    "            if nesterov:\n",
    "                p_new = p + mu * v_new - (1 - mu) * learning_rate * g\n",
    "            else:\n",
    "                p_new = p + v_new\n",
    "            updates.append((ms, ms_new))\n",
    "            updates.append((v, v_new))\n",
    "            updates.append((p, p_new))\n",
    "                \n",
    "        return updates\n",
    "    \n",
    "    if rho:\n",
    "        updates = RMSprop(cost, nn.params, learning_rate=learning_rate, rho=rho, mu=mu, nesterov=nesterov)\n",
    "    else:\n",
    "        # compute the gradient of cost with respect to theta (sotred in params)\n",
    "        # the resulting gradients will be stored in a list gparams\n",
    "        gparams = [T.grad(cost, param) for param in nn.params]\n",
    "\n",
    "        # specify how to update the parameters of the model as a list of\n",
    "        # (variable, update expression) pairs\n",
    "\n",
    "        updates = [\n",
    "            (param, param - learning_rate * gparam)\n",
    "            for param, gparam in zip(nn.params, gparams)\n",
    "        ]\n",
    "    \n",
    "    def inspect_inputs(i, node, fn):\n",
    "        print i, node, \"input(s) value(s):\", [input[0] for input in fn.inputs]\n",
    "\n",
    "    def inspect_outputs(i, node, fn):\n",
    "        print \"output(s) value(s):\", [output[0] for output in fn.outputs]\n",
    "\n",
    "    # compiling a Theano function `train_model` that returns the cost, but\n",
    "    # in the same time updates the parameter of the model based on the rules\n",
    "    # defined in `updates`\n",
    "    train_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if mult_ys:\n",
    "        valid_mse = nn.valid_mse(y)\n",
    "    else:\n",
    "        valid_mse = cost\n",
    "    \n",
    "    validate_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=valid_mse,\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size:(index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size:(index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ###############\n",
    "    # TRAIN MODEL #\n",
    "    ###############\n",
    "    print '... training'\n",
    "\n",
    "    epoch = 0 \n",
    "\n",
    "    if valid_dataset:\n",
    "        valid_mse = np.zeros(n_epochs)\n",
    "\n",
    "    while (epoch < n_epochs):\n",
    "        for minibatch_index in xrange(n_train_batches):\n",
    "            \n",
    "            minibatch_avg_cost = train_model(minibatch_index)\n",
    "            \n",
    "        if valid_dataset:\n",
    "            validation_losses = [validate_model(i) for i in xrange(n_valid_batches)]\n",
    "            this_validation_loss = np.mean(validation_losses)\n",
    "            valid_mse[epoch] = this_validation_loss\n",
    "            print(\n",
    "                'epoch %i, validation error %f' %\n",
    "                (\n",
    "                    epoch,\n",
    "                    this_validation_loss,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        epoch = epoch + 1\n",
    "\n",
    "    if valid_dataset:\n",
    "        return nn, x, valid_mse\n",
    "    return nn, x\n",
    "\n",
    "def test_nn(nn, nnx, test_data):\n",
    "    print 'testing'\n",
    "    test_batch_size = 1\n",
    "    test_set_x, test_set_y = shared_dataset(test_data)\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "    x = nnx   # input data from visual neurons\n",
    "    test_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=nn.y_pred,\n",
    "        givens={\n",
    "            x: test_set_x[index * test_batch_size: (index + 1) * test_batch_size]\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    true_ys = test_set_y.get_value()\n",
    "    pred_ys = np.zeros((len(true_ys), 2))\n",
    "    for i in range(len(true_ys)):\n",
    "        pred_ys[i] = test_model(i)\n",
    "        #print test_model(i)[0], true_ys[i]\n",
    "        #print test_model(i)[0] * 90, true_ys[i]\n",
    "    \n",
    "    #print nn.get_params()\n",
    "    return pred_ys, true_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 trials per contrast level\n",
      "3000 trials per contrast level\n",
      "30000 trials per contrast level\n",
      "100 trials per contrast level\n",
      "... building the model\n",
      "... training\n",
      "epoch 0, validation error 974.018282\n",
      "epoch 1, validation error 715.963227\n",
      "epoch 2, validation error 622.572728\n",
      "epoch 3, validation error 565.799241\n",
      "epoch 4, validation error 529.839920\n",
      "epoch 5, validation error 507.512102\n",
      "epoch 6, validation error 489.247489\n",
      "epoch 7, validation error 477.050087\n",
      "epoch 8, validation error 466.878515\n",
      "epoch 9, validation error 461.860719\n",
      "epoch 10, validation error 460.742751\n",
      "epoch 11, validation error 460.542752\n",
      "epoch 12, validation error 459.028885\n",
      "epoch 13, validation error 456.767129\n",
      "epoch 14, validation error 455.623355\n",
      "epoch 15, validation error 453.135185\n",
      "epoch 16, validation error 450.831577\n",
      "epoch 17, validation error 448.938438\n",
      "epoch 18, validation error 448.080171\n",
      "epoch 19, validation error 445.987136\n",
      "epoch 20, validation error 443.610451\n",
      "epoch 21, validation error 440.099394\n",
      "epoch 22, validation error 438.119403\n",
      "epoch 23, validation error 434.553617\n",
      "epoch 24, validation error 431.054047\n",
      "epoch 25, validation error 427.589702\n",
      "epoch 26, validation error 424.411870\n",
      "epoch 27, validation error 422.550411\n",
      "epoch 28, validation error 419.878302\n",
      "epoch 29, validation error 417.042614\n",
      "epoch 30, validation error 414.336499\n",
      "epoch 31, validation error 411.865252\n",
      "epoch 32, validation error 409.418515\n",
      "epoch 33, validation error 407.174295\n",
      "epoch 34, validation error 405.620864\n",
      "epoch 35, validation error 403.295386\n",
      "epoch 36, validation error 401.318829\n",
      "epoch 37, validation error 399.026417\n",
      "epoch 38, validation error 397.187874\n",
      "epoch 39, validation error 394.319656\n",
      "epoch 40, validation error 392.216955\n",
      "epoch 41, validation error 389.740684\n",
      "epoch 42, validation error 387.520297\n",
      "epoch 43, validation error 385.588857\n",
      "epoch 44, validation error 383.519395\n",
      "epoch 45, validation error 381.524451\n",
      "epoch 46, validation error 379.939442\n",
      "epoch 47, validation error 378.909694\n",
      "epoch 48, validation error 377.312446\n",
      "epoch 49, validation error 376.099805\n",
      "epoch 50, validation error 374.609355\n",
      "epoch 51, validation error 373.307555\n",
      "epoch 52, validation error 372.163624\n",
      "epoch 53, validation error 371.011353\n",
      "epoch 54, validation error 370.048929\n",
      "epoch 55, validation error 369.659591\n",
      "epoch 56, validation error 368.351062\n",
      "epoch 57, validation error 367.619962\n",
      "epoch 58, validation error 366.635696\n",
      "epoch 59, validation error 365.618500\n",
      "epoch 60, validation error 364.764594\n",
      "epoch 61, validation error 364.273548\n",
      "epoch 62, validation error 363.716402\n",
      "epoch 63, validation error 362.538281\n",
      "epoch 64, validation error 361.688868\n",
      "epoch 65, validation error 361.039306\n",
      "epoch 66, validation error 360.057930\n",
      "epoch 67, validation error 359.246561\n",
      "epoch 68, validation error 358.629792\n",
      "epoch 69, validation error 357.740944\n",
      "epoch 70, validation error 356.753558\n",
      "epoch 71, validation error 355.874218\n",
      "epoch 72, validation error 355.367502\n",
      "epoch 73, validation error 354.378934\n",
      "epoch 74, validation error 353.436973\n",
      "epoch 75, validation error 352.959296\n",
      "epoch 76, validation error 351.861671\n",
      "epoch 77, validation error 351.328054\n",
      "epoch 78, validation error 350.355340\n",
      "epoch 79, validation error 349.402185\n",
      "epoch 80, validation error 348.771870\n",
      "epoch 81, validation error 347.993481\n",
      "epoch 82, validation error 347.141170\n",
      "epoch 83, validation error 346.054739\n",
      "epoch 84, validation error 345.200974\n",
      "epoch 85, validation error 344.149846\n",
      "epoch 86, validation error 343.022976\n",
      "epoch 87, validation error 342.096803\n",
      "epoch 88, validation error 341.411019\n",
      "epoch 89, validation error 340.488288\n",
      "epoch 90, validation error 339.568862\n",
      "epoch 91, validation error 339.104743\n",
      "epoch 92, validation error 338.764200\n",
      "epoch 93, validation error 338.277977\n",
      "epoch 94, validation error 338.036454\n",
      "epoch 95, validation error 337.128405\n",
      "epoch 96, validation error 336.597804\n",
      "epoch 97, validation error 335.789577\n",
      "epoch 98, validation error 335.064953\n",
      "epoch 99, validation error 334.509066\n",
      "... building the model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ca092987fb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtd_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                         \u001b[0mnn_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtd_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_nn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mnns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtd_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_nn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-9c53727afaa5>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(train_dataset, valid_dataset, n_hidden, learning_rate, n_epochs, batch_size, linear, mult_ys, rho, nesterov, mu, n_in, n_out)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# compute the gradient of cost with respect to theta (sotred in params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# the resulting gradients will be stored in a list gparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mgparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# specify how to update the parameters of the model as a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     rval = _populate_grad_dict(var_to_app_to_idx,\n\u001b[0;32m--> 545\u001b[0;31m                                grad_dict, wrt, cost_name)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36m_populate_grad_dict\u001b[0;34m(var_to_app_to_idx, grad_dict, wrt, cost_name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m     \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwrt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0moutput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccess_grad_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# list of bools indicating if each output is connected to the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                         \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess_term_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# Check that the gradient term for this input has the right shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                     \u001b[0morig_ipt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0morig_ipt_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_debug_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_ipt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \"\"\"\n\u001b[1;32m    506\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/compile/ops.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHalpern/anaconda/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, op, inputs, outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m## filter outputs to make sure each element is a Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "td_sizes = [2700, 27000, 270000]\n",
    "td_types = [True, False]\n",
    "for td_s in td_sizes:\n",
    "    for td_t in td_types:\n",
    "        train_data[td_s, td_t] = generate_trainset(td_s, highlow=td_t, discrete_c=3, low=.3, high=.7)\n",
    "valid_data = generate_testset(900, discrete_c=3, low=.3, high=.7)\n",
    "lrs = [.01, .005, .001, .0005, .0001, .00001]\n",
    "rhos = [0, .75, .9, .95, .99, .999]\n",
    "mus = [0, .75, .9, .95, .99, .999]\n",
    "nests = [True, False]\n",
    "nrows = len(td_sizes) * len(td_types) * len(lrs) * len(rhos) * len(mus) * len(nests)\n",
    "nn_df = pd.DataFrame(index=np.arange(0, nrows), columns=('training_type', 'training_size', 'lr', 'rho', 'mu', 'nest', 'valid_nn') )\n",
    "nns = {}\n",
    "ind = 0\n",
    "for td_s in td_sizes:\n",
    "    for td_t in td_types:\n",
    "        for lr in lrs:\n",
    "            for rho in rhos:\n",
    "                for mu in mus:\n",
    "                    for n in nests:\n",
    "                        nn, nnx, valid_nn = train_nn(train_data[td_s, td_t], valid_dataset=valid_data, n_hidden=20, learning_rate=lr, n_epochs=100, rho=rho, mu=mu, nesterov=n)\n",
    "                        nn_df.loc[ind] = [td_s, td_t, lr, rho, mu, n, valid_nn[99]]\n",
    "                        nns[td_s, td_t, lr, rho, mu, n] = nn, nnx, valid_nn\n",
    "                        ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = (nn_df, nns)\n",
    "pkl_file = open('nn_optim.pkl', 'wb')\n",
    "pickle.dump(output, pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_file = open('nn_optim.pkl', 'rb')\n",
    "nn_df, nns = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>rho</th>\n",
       "      <th>mu</th>\n",
       "      <th>nest</th>\n",
       "      <th>valid_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td>  0.99</td>\n",
       "      <td>    0</td>\n",
       "      <td> False</td>\n",
       "      <td> 23.62539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td>  0.99</td>\n",
       "      <td> 0.95</td>\n",
       "      <td>  True</td>\n",
       "      <td> 24.06649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td> 0.999</td>\n",
       "      <td> 0.95</td>\n",
       "      <td>  True</td>\n",
       "      <td> 25.07611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td>  0.99</td>\n",
       "      <td>  0.9</td>\n",
       "      <td>  True</td>\n",
       "      <td>   25.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>  0.001</td>\n",
       "      <td> 0.999</td>\n",
       "      <td>  0.9</td>\n",
       "      <td>  True</td>\n",
       "      <td> 26.92505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.95</td>\n",
       "      <td>  0.9</td>\n",
       "      <td>  True</td>\n",
       "      <td> 27.41485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td>  0.95</td>\n",
       "      <td> 0.95</td>\n",
       "      <td> False</td>\n",
       "      <td>  27.6143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td>  0.75</td>\n",
       "      <td>    0</td>\n",
       "      <td>  True</td>\n",
       "      <td> 27.88683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td> 0.0005</td>\n",
       "      <td> 0.999</td>\n",
       "      <td> 0.95</td>\n",
       "      <td> False</td>\n",
       "      <td> 28.00329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.75</td>\n",
       "      <td> 0.75</td>\n",
       "      <td> False</td>\n",
       "      <td> 28.20586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.75</td>\n",
       "      <td>    0</td>\n",
       "      <td> False</td>\n",
       "      <td> 28.59583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.75</td>\n",
       "      <td> 0.95</td>\n",
       "      <td> False</td>\n",
       "      <td> 28.69929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.99</td>\n",
       "      <td> 0.75</td>\n",
       "      <td>  True</td>\n",
       "      <td> 28.79722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.95</td>\n",
       "      <td> 0.75</td>\n",
       "      <td> False</td>\n",
       "      <td> 28.82443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>  0.001</td>\n",
       "      <td>  0.95</td>\n",
       "      <td> 0.95</td>\n",
       "      <td>  True</td>\n",
       "      <td> 28.87836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr    rho    mu   nest  valid_nn\n",
       "265  0.0005   0.99     0  False  23.62539\n",
       "270  0.0005   0.99  0.95   True  24.06649\n",
       "282  0.0005  0.999  0.95   True  25.07611\n",
       "268  0.0005   0.99   0.9   True    25.766\n",
       "208   0.001  0.999   0.9   True  26.92505\n",
       "184   0.001   0.95   0.9   True  27.41485\n",
       "259  0.0005   0.95  0.95  False   27.6143\n",
       "228  0.0005   0.75     0   True  27.88683\n",
       "283  0.0005  0.999  0.95  False  28.00329\n",
       "159   0.001   0.75  0.75  False  28.20586\n",
       "157   0.001   0.75     0  False  28.59583\n",
       "163   0.001   0.75  0.95  False  28.69929\n",
       "194   0.001   0.99  0.75   True  28.79722\n",
       "183   0.001   0.95  0.75  False  28.82443\n",
       "186   0.001   0.95  0.95   True  28.87836"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_df.sort('valid_nn', ascending=1)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222 trials per contrast level\n",
      "33 trials per contrast level\n",
      "300 trials per contrast level\n",
      "... building the model\n",
      "... training\n",
      "epoch 0, validation error 491.003906\n",
      "epoch 1, validation error 305.005266\n",
      "epoch 2, validation error 252.444780\n",
      "epoch 3, validation error 227.755945\n",
      "epoch 4, validation error 211.584612\n",
      "epoch 5, validation error 200.027390\n",
      "epoch 6, validation error 190.767461\n",
      "epoch 7, validation error 182.573345\n",
      "epoch 8, validation error 175.295962\n",
      "epoch 9, validation error 169.075167\n",
      "epoch 10, validation error 161.931297\n",
      "epoch 11, validation error 154.844404\n",
      "epoch 12, validation error 146.641978\n",
      "epoch 13, validation error 137.978208\n",
      "epoch 14, validation error 129.139005\n",
      "epoch 15, validation error 119.998368\n",
      "epoch 16, validation error 109.894488\n",
      "epoch 17, validation error 99.293459\n",
      "epoch 18, validation error 89.477842\n",
      "epoch 19, validation error 79.675361\n",
      "epoch 20, validation error 71.269097\n",
      "epoch 21, validation error 64.083121\n",
      "epoch 22, validation error 58.065896\n",
      "epoch 23, validation error 53.427707\n",
      "epoch 24, validation error 49.697452\n",
      "epoch 25, validation error 47.193953\n",
      "epoch 26, validation error 45.461343\n",
      "epoch 27, validation error 43.902569\n",
      "epoch 28, validation error 42.714439\n",
      "epoch 29, validation error 41.587949\n",
      "epoch 30, validation error 40.344506\n",
      "epoch 31, validation error 39.333611\n",
      "epoch 32, validation error 38.505130\n",
      "epoch 33, validation error 37.631545\n",
      "epoch 34, validation error 37.099394\n",
      "epoch 35, validation error 36.623183\n",
      "epoch 36, validation error 36.036883\n",
      "epoch 37, validation error 35.696887\n",
      "epoch 38, validation error 35.335993\n",
      "epoch 39, validation error 34.931705\n",
      "epoch 40, validation error 34.659435\n",
      "epoch 41, validation error 34.395195\n",
      "epoch 42, validation error 34.099213\n",
      "epoch 43, validation error 33.759263\n",
      "epoch 44, validation error 33.518847\n",
      "epoch 45, validation error 33.132209\n",
      "epoch 46, validation error 33.244684\n",
      "epoch 47, validation error 32.978259\n",
      "epoch 48, validation error 32.725375\n",
      "epoch 49, validation error 32.425009\n",
      "epoch 50, validation error 32.348834\n",
      "epoch 51, validation error 32.231942\n",
      "epoch 52, validation error 32.077626\n",
      "epoch 53, validation error 32.041232\n",
      "epoch 54, validation error 31.819820\n",
      "epoch 55, validation error 31.729606\n",
      "epoch 56, validation error 31.534010\n",
      "epoch 57, validation error 31.514501\n",
      "epoch 58, validation error 31.463616\n",
      "epoch 59, validation error 31.434517\n",
      "epoch 60, validation error 31.288797\n",
      "epoch 61, validation error 31.239066\n",
      "epoch 62, validation error 31.201751\n",
      "epoch 63, validation error 31.014870\n",
      "epoch 64, validation error 30.890377\n",
      "epoch 65, validation error 30.800929\n",
      "epoch 66, validation error 30.757334\n",
      "epoch 67, validation error 30.789739\n",
      "epoch 68, validation error 30.758566\n",
      "epoch 69, validation error 30.678097\n",
      "epoch 70, validation error 30.475842\n",
      "epoch 71, validation error 30.450731\n",
      "epoch 72, validation error 30.441804\n",
      "epoch 73, validation error 30.349169\n",
      "epoch 74, validation error 30.290471\n",
      "epoch 75, validation error 30.306399\n",
      "epoch 76, validation error 30.306768\n",
      "epoch 77, validation error 30.287379\n",
      "epoch 78, validation error 30.210589\n",
      "epoch 79, validation error 30.241915\n",
      "epoch 80, validation error 30.208996\n",
      "epoch 81, validation error 30.231076\n",
      "epoch 82, validation error 30.192123\n",
      "epoch 83, validation error 30.210623\n",
      "epoch 84, validation error 30.137132\n",
      "epoch 85, validation error 30.096556\n",
      "epoch 86, validation error 29.985754\n",
      "epoch 87, validation error 29.851061\n",
      "epoch 88, validation error 29.766762\n",
      "epoch 89, validation error 29.686666\n",
      "epoch 90, validation error 29.623421\n",
      "epoch 91, validation error 29.567335\n",
      "epoch 92, validation error 29.510479\n",
      "epoch 93, validation error 29.361760\n",
      "epoch 94, validation error 29.169236\n",
      "epoch 95, validation error 29.061227\n",
      "epoch 96, validation error 29.018618\n",
      "epoch 97, validation error 28.905882\n",
      "epoch 98, validation error 28.811704\n",
      "epoch 99, validation error 28.918345\n",
      "... building the model\n",
      "... training\n",
      "epoch 0, validation error 464.939520\n",
      "epoch 1, validation error 297.796707\n",
      "epoch 2, validation error 255.748569\n",
      "epoch 3, validation error 234.266439\n",
      "epoch 4, validation error 222.307059\n",
      "epoch 5, validation error 212.416733\n",
      "epoch 6, validation error 206.043513\n",
      "epoch 7, validation error 201.484325\n",
      "epoch 8, validation error 196.993391\n",
      "epoch 9, validation error 191.937414\n",
      "epoch 10, validation error 187.423464\n",
      "epoch 11, validation error 183.385299\n",
      "epoch 12, validation error 178.913748\n",
      "epoch 13, validation error 174.607082\n",
      "epoch 14, validation error 169.604589\n",
      "epoch 15, validation error 164.335416\n",
      "epoch 16, validation error 158.493241\n",
      "epoch 17, validation error 152.084633\n",
      "epoch 18, validation error 145.026676\n",
      "epoch 19, validation error 137.054501\n",
      "epoch 20, validation error 128.551817\n",
      "epoch 21, validation error 119.207806\n",
      "epoch 22, validation error 108.720000\n",
      "epoch 23, validation error 97.822199\n",
      "epoch 24, validation error 87.151304\n",
      "epoch 25, validation error 76.642737\n",
      "epoch 26, validation error 67.727402\n",
      "epoch 27, validation error 60.343014\n",
      "epoch 28, validation error 54.411393\n",
      "epoch 29, validation error 49.943202\n",
      "epoch 30, validation error 46.777099\n",
      "epoch 31, validation error 44.691170\n",
      "epoch 32, validation error 43.015993\n",
      "epoch 33, validation error 41.837991\n",
      "epoch 34, validation error 40.858996\n",
      "epoch 35, validation error 40.269263\n",
      "epoch 36, validation error 39.757533\n",
      "epoch 37, validation error 39.124720\n",
      "epoch 38, validation error 38.627293\n",
      "epoch 39, validation error 38.121343\n",
      "epoch 40, validation error 37.721817\n",
      "epoch 41, validation error 37.319577\n",
      "epoch 42, validation error 36.824320\n",
      "epoch 43, validation error 36.494786\n",
      "epoch 44, validation error 36.146129\n",
      "epoch 45, validation error 35.948325\n",
      "epoch 46, validation error 35.676362\n",
      "epoch 47, validation error 35.418402\n",
      "epoch 48, validation error 35.159619\n",
      "epoch 49, validation error 34.928520\n",
      "epoch 50, validation error 34.705049\n",
      "epoch 51, validation error 34.512218\n",
      "epoch 52, validation error 34.114212\n",
      "epoch 53, validation error 33.951044\n",
      "epoch 54, validation error 33.777841\n",
      "epoch 55, validation error 33.632816\n",
      "epoch 56, validation error 33.467327\n",
      "epoch 57, validation error 33.328367\n",
      "epoch 58, validation error 33.072297\n",
      "epoch 59, validation error 32.945544\n",
      "epoch 60, validation error 32.836427\n",
      "epoch 61, validation error 32.672965\n",
      "epoch 62, validation error 32.796791\n",
      "epoch 63, validation error 32.431886\n",
      "epoch 64, validation error 32.288100\n",
      "epoch 65, validation error 32.110086\n",
      "epoch 66, validation error 32.102287\n",
      "epoch 67, validation error 31.872139\n",
      "epoch 68, validation error 31.738845\n",
      "epoch 69, validation error 31.630057\n",
      "epoch 70, validation error 31.486425\n",
      "epoch 71, validation error 31.380385\n",
      "epoch 72, validation error 31.249205\n",
      "epoch 73, validation error 31.154809\n",
      "epoch 74, validation error 31.053006\n",
      "epoch 75, validation error 30.857914\n",
      "epoch 76, validation error 30.756509\n",
      "epoch 77, validation error 30.621249\n",
      "epoch 78, validation error 30.501404\n",
      "epoch 79, validation error 30.398257\n",
      "epoch 80, validation error 30.288186\n",
      "epoch 81, validation error 30.183190\n",
      "epoch 82, validation error 30.094779\n",
      "epoch 83, validation error 29.970483\n",
      "epoch 84, validation error 29.836819\n",
      "epoch 85, validation error 29.809018\n",
      "epoch 86, validation error 29.668642\n",
      "epoch 87, validation error 29.490537\n",
      "epoch 88, validation error 29.399567\n",
      "epoch 89, validation error 29.344739\n",
      "epoch 90, validation error 29.236057\n",
      "epoch 91, validation error 29.154426\n",
      "epoch 92, validation error 29.099481\n",
      "epoch 93, validation error 29.025032\n",
      "epoch 94, validation error 28.921326\n",
      "epoch 95, validation error 28.763589\n",
      "epoch 96, validation error 28.680860\n",
      "epoch 97, validation error 28.625870\n",
      "epoch 98, validation error 28.552822\n",
      "epoch 99, validation error 28.438387\n"
     ]
    }
   ],
   "source": [
    "train_data_1 = generate_testset(19998, discrete_c=3, low=.3, high=.7)\n",
    "valid_data_1 = generate_testset(297, discrete_c=3, low=.3, high=.7)\n",
    "valid_data_2 = generate_testset(2700, discrete_c=3, low=.3, high=.7)\n",
    "nn, nnx, valid_nn = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=.0005, n_epochs=100, rho=.99, mu=.95, nesterov=True)\n",
    "nn, nnx, valid_nn = train_nn(train_data_1, valid_dataset=valid_data_2, n_hidden=20, learning_rate=.0005, n_epochs=100, rho=.99, mu=.95, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
