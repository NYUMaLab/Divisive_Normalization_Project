{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Describe training. Different ways of training, generalization across gains. Bias and variance as a function of Delta s and gains (think abpout how to plot smartly, to avoid having too many plots)\n",
    "    \n",
    "Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(//anaconda/lib/python2.7/site-packages/matplotlib/_png.so, 2): Library not loaded: @loader_path/../../../libpng15.15.dylib\n  Referenced from: //anaconda/lib/python2.7/site-packages/matplotlib/_png.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c04ed848b1bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoisson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallow_rasterization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbackend_bases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_bbox\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtight_bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextpath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtextpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/matplotlib/textpath.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mft2font\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFT2Font\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKERNING_DEFAULT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOAD_NO_HINTING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mft2font\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOAD_TARGET_LIGHT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmathtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMathTextParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdviread\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFontProperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/matplotlib/mathtext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_png\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;31m####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(//anaconda/lib/python2.7/site-packages/matplotlib/_png.so, 2): Library not loaded: @loader_path/../../../libpng15.15.dylib\n  Referenced from: //anaconda/lib/python2.7/site-packages/matplotlib/_png.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.patches as mpatches\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "\n",
    "nneuron = 61\n",
    "min_angle = -90\n",
    "max_angle = 90\n",
    "sprefs = np.linspace(min_angle, max_angle, nneuron)\n",
    "eps = np.finfo(np.float64).eps\n",
    "sigtc_sq = float(10**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    shape = (len(x) for x in arrays)\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    ix = np.indices(shape)\n",
    "    ix = ix.reshape(len(arrays), -1).T\n",
    "\n",
    "    if out is None:\n",
    "        out = np.empty_like(ix, dtype=dtype)\n",
    "\n",
    "    for n, arr in enumerate(arrays):\n",
    "        out[:, n] = arrays[n][ix[:, n]]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_s(ndata, sort):\n",
    "    s = np.random.rand(2, ndata) * 120 - 60\n",
    "    if sort:\n",
    "        s = np.sort(s, axis=0)\n",
    "    return s[0], s[1]\n",
    "\n",
    "def random_c(ndata, ndims, low, high, sort):\n",
    "    c_range = high - low\n",
    "    if ndims == 1:\n",
    "        c = np.random.rand(ndims, ndata)[0] * c_range + low\n",
    "    else:\n",
    "        c = np.random.rand(ndims, ndata) * c_range + low\n",
    "    if sort:\n",
    "        c = np.sort(c, axis=0)\n",
    "    return c\n",
    "    \n",
    "def generate_popcode_data(ndata, nneuron, sigtc_sq, r_max, noise, sort, s_0, s_1, c_0, c_1, c_50=13.1):\n",
    "    c_rms = np.sqrt(np.square(c_0) + np.square(c_1))\n",
    "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
    "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_0 = c_0 * s_0t.T\n",
    "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_1 = c_1 * s_1t.T\n",
    "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
    "    r = r_max * (stim_0 + stim_1)\n",
    "    r = r.T\n",
    "    s = np.array((s_0, s_1)).T\n",
    "    s = s/90\n",
    "    c = np.array((c_0, c_1)).T\n",
    "    if noise == \"poisson\":\n",
    "        r = np.random.poisson(r) + 0.0\n",
    "    return r, s, c\n",
    "\n",
    "def generate_trainset(ndata, highlow=False, discrete_c=None, low=.3, high=.7, r_max=10):\n",
    "    s_0, s_1 = random_s(ndata, True)\n",
    "    if highlow:\n",
    "        c_0, c_1 = np.concatenate((np.ones((2, ndata/2)) * low, np.ones((2, ndata/2)) * high), axis=1)\n",
    "    elif discrete_c:\n",
    "        cs = np.linspace(low, high, discrete_c)\n",
    "        perm_cs = cartesian((cs, cs)).T\n",
    "        c_0, c_1 = np.repeat(perm_cs, ndata/(discrete_c**2), axis=1)\n",
    "        print ndata/(discrete_c**2), \"trials per contrast level\"\n",
    "        if ndata%(discrete_c**2) != 0:\n",
    "            print \"Not divisible, only generated\", ndata / (discrete_c**2) * (discrete_c**2), \"trials\"\n",
    "        ndata = ndata / (discrete_c**2) * (discrete_c**2)\n",
    "    else:\n",
    "        c_0, c_1 = np.ones((2, ndata)) * .5\n",
    "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
    "    return r, s, c\n",
    "\n",
    "def generate_testset(ndata, stim_0=None, stim_1=None, con_0=None, con_1=None, discrete_c=None, low=.5, high=.5, r_max=10):\n",
    "    if con_0:\n",
    "        c_0 = np.ones(ndata) * con_0\n",
    "        c_1 = np.ones(ndata) * con_1\n",
    "    else:\n",
    "        c_range = high - low\n",
    "        if discrete_c:\n",
    "            cs = np.linspace(low, high, discrete_c)\n",
    "            perm_cs = cartesian((cs, cs)).T\n",
    "            c_0, c_1 = np.repeat(perm_cs, ndata/(discrete_c**2), axis=1)\n",
    "            print ndata/(discrete_c**2), \"trials per contrast level\"\n",
    "            if ndata%(discrete_c**2) != 0:\n",
    "                print \"Not divisible, only generated\", ndata / (discrete_c**2) * (discrete_c**2), \"trials\"\n",
    "            ndata = ndata / (discrete_c**2) * (discrete_c**2)\n",
    "        else:\n",
    "            c_0, c_1 = np.random.rand(2, ndata) * c_range + low\n",
    "    if not stim_0:\n",
    "        s_0, s_1 = random_s(ndata, True)\n",
    "    else:\n",
    "        s_0, s_1 = np.ones((2, ndata))\n",
    "        s_0 = s_0 * stim_0\n",
    "        s_1 = s_1 * stim_1\n",
    "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
    "    return r, s, c\n",
    "\n",
    "def generate_trainset_cat(ndata, low=.3, high=1.3, crange=.5, r_max=10):\n",
    "    numvec = np.random.binomial(1, .5, size=ndata).astype(int)\n",
    "    c_0 = random_c(ndata, 1, high, high+crange, True)\n",
    "    c_1 = random_c(ndata, 1, low, low+crange, True)\n",
    "    s_0, s_1 = np.random.rand(2, ndata) * 120 - 60\n",
    "    r, numvec, s, c  = generate_popcode_data_cat(ndata, numvec, nneuron, sigtc_sq, c_50, r_max, \"poisson\", s_0, s_1, c_0, c_1)\n",
    "    y = s[range(ndata), numvec]\n",
    "    return r, y, s, c, numvec \n",
    "    \n",
    "def generate_popcode_data_cat(ndata, numvec, nneuron, sigtc_sq, c_50, r_max, noise, s_0, s_1, c_0, c_1):\n",
    "    c0vec = c_0 * np.ones(ndata)\n",
    "    c1vec = c_1 * numvec\n",
    "    c_rms = np.sqrt(np.square(c0vec) + np.square(c1vec))\n",
    "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
    "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_0 = c0vec * s_0t.T\n",
    "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_1 = c1vec * s_1t.T\n",
    "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
    "    r = r_max * (stim_0 + stim_1)/(c_rms)\n",
    "    #r = r_max * (stim_0 + stim_1)\n",
    "    r = r.T\n",
    "    s = np.array((s_0, s_1)).T\n",
    "    s = s/90\n",
    "    c = np.array((c_0, c_1)).T\n",
    "    if noise == \"poisson\":\n",
    "        r = np.random.poisson(r) + 0.0\n",
    "    return r, numvec, s, c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sprefs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-61dbeb0a22e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlik_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msprefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msprefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigtc_sq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigtc_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msprefs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msprefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ms_0t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnneuron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msprefs_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigtc_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstim_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms_0t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms_1t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnneuron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msprefs_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigtc_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sprefs' is not defined"
     ]
    }
   ],
   "source": [
    "def lik_means(s_1, s_2, c_0=.5, c_1=.5, sprefs=sprefs, sigtc_sq=sigtc_sq, r_max=10):\n",
    "    sprefs_data = np.tile(sprefs, (len(s_1), 1))\n",
    "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_0 = c_0 * s_0t.T\n",
    "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_2, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
    "    stim_1 = c_1 * s_1t.T\n",
    "    r = r_max * (stim_0 + stim_1)\n",
    "    return r.T\n",
    "def posterior(r, means, s1_grid, s2_grid):\n",
    "    ns_liks = poisson.pmf(r, mu=means)\n",
    "    stim_liks = np.prod(ns_liks, axis=1)\n",
    "    #p_s = 2/14400\n",
    "    #logp_s = np.log(p_s)\n",
    "    logp_s = -3.8573325\n",
    "    loglik = np.sum(np.log(ns_liks), axis=1)\n",
    "    mean1 = np.sum(s1_grid * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    mean2 = np.sum(s2_grid * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    expsquare1 = np.sum(np.square(s1_grid) * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    expsquare2 = np.sum(np.square(s2_grid) * np.exp(loglik + logp_s)/np.sum(np.exp(loglik + logp_s)))\n",
    "    var1 = expsquare1 - np.square(mean1)\n",
    "    var2 = expsquare2 - np.square(mean2)\n",
    "    return mean1, mean2, var1, var2\n",
    "def posterior_setup(low=.3, high=.7, discrete_c = 3, num_s=100, r_max=10):\n",
    "    grid = np.linspace(-60, 60, num_s)\n",
    "    s1s = np.concatenate([[grid[i]]*(num_s-i) for i in range(num_s)])\n",
    "    cs = np.linspace(low, high, discrete_c)\n",
    "    s1_grid, c1_grid, c2_grid = cartesian((s1s, cs, cs)).T\n",
    "    s2s = np.concatenate([grid[i:num_s+1] for i in range(num_s)])\n",
    "    s2_grid = np.repeat(s2s, (discrete_c**2), axis=0)\n",
    "    means = lik_means(s1_grid, s2_grid, c_0=c1_grid, c_1=c2_grid, r_max=r_max)\n",
    "    partial_post = partial(posterior, means=means, s1_grid=s1_grid, s2_grid=s2_grid)\n",
    "    return partial_post\n",
    "def get_posteriors(r, post_func):\n",
    "    posteriors = {'mean_s1': None, 'mean_s2': None, 'var_s1': None, 'var_s2': None}\n",
    "    p = np.array([post_func(r[i]) for i in range(len(r))]).T\n",
    "    posteriors['mean_s1'], posteriors['mean_s2'], posteriors['var_s1'], posteriors['var_s2'] = p\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multilayer ReLU net\n",
    "\"\"\"\n",
    "\n",
    "def relu(x):\n",
    "    return theano.tensor.switch(x<0, 0, x)\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out, W=None, b=None,\n",
    "                 activation=T.nnet.sigmoid):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        :type rng: np.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.dmatrix\n",
    "        :param input: a symbolic tensor of shape (n_examples, n_in)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: theano.Op or function\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        if W is None:\n",
    "            W_values = (1/np.sqrt(n_in)) * np.random.randn(n_in, n_out)\n",
    "            \n",
    "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
    "\n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        lin_output = T.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if activation is None\n",
    "            else activation(lin_output)\n",
    "        )\n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "class MLP(object):\n",
    "\n",
    "\n",
    "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
    "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
    "\n",
    "        :type rng: np.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "        architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "        which the datapoints lie\n",
    "\n",
    "        :type n_hidden: int\n",
    "        :param n_hidden: number of hidden units\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "        which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.hiddenLayer1 = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=input,\n",
    "            n_in=n_in,\n",
    "            n_out=n_hidden,\n",
    "            #activation=T.nnet.sigmoid\n",
    "            activation=relu\n",
    "        )\n",
    "        \n",
    "        self.hiddenLayer2 = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=self.hiddenLayer1.output,\n",
    "            n_in=n_hidden,\n",
    "            n_out=n_out,\n",
    "            #activation=relu\n",
    "            activation=None\n",
    "        )\n",
    "        \n",
    "        self.y_pred = self.hiddenLayer2.output\n",
    "        \n",
    "        # the parameters of the model are the parameters of the two layers it is made out of\n",
    "        self.params = self.hiddenLayer1.params + self.hiddenLayer2.params\n",
    "    \n",
    "    def get_params(self):\n",
    "\n",
    "        params = {}\n",
    "        for param in self.params:\n",
    "            name = param.name\n",
    "            if name in params:\n",
    "                name = name, 2\n",
    "            params[name] = param.get_value()\n",
    "        return params\n",
    "    \n",
    "    def mse(self, y):\n",
    "        # error between output and target\n",
    "        if y.ndim == 1:\n",
    "            se = (self.y_pred.T - y)**2\n",
    "        else:\n",
    "            se = T.sum((self.y_pred - y)**2, axis=1)\n",
    "        return T.mean(se)\n",
    "        \n",
    "    \n",
    "    def valid_mse(self, y):\n",
    "        if y.ndim == 1:\n",
    "            se = (self.y_pred.T * 90 - y * 90)**2\n",
    "        else:\n",
    "            se = T.sum((self.y_pred * 90 - y * 90)**2, axis=1)\n",
    "        return T.mean(se)\n",
    "\n",
    "    \n",
    "class Perceptron(object):\n",
    "\n",
    "\n",
    "    def __init__(self, rng, input, n_in, n_out):\n",
    "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
    "\n",
    "        :type rng: np.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "        architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "        which the datapoints lie\n",
    "\n",
    "        :type n_hidden: int\n",
    "        :param n_hidden: number of hidden units\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "        which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.layer = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=input,\n",
    "            n_in=n_in,\n",
    "            n_out=n_out,\n",
    "            #activation=T.nnet.sigmoid\n",
    "            activation=relu\n",
    "        )\n",
    "        \n",
    "        self.y_pred = self.layer.output\n",
    "        \n",
    "        # the parameters of the model are the parameters of the two layers it is made out of\n",
    "        self.params = self.layer.params\n",
    "        \n",
    "    def get_params(self):\n",
    "\n",
    "        params = {}\n",
    "        for param in self.params:\n",
    "            name = param.name\n",
    "            if name in params:\n",
    "                name = name, 2\n",
    "            params[name] = param.get_value()\n",
    "        return params\n",
    "    \n",
    "    def mse(self, y):\n",
    "        # error between output and target\n",
    "        if y.ndim == 1:\n",
    "            se = (self.y_pred.T - y)**2\n",
    "        else:\n",
    "            se = T.sum((self.y_pred - y)**2, axis=1)\n",
    "        return T.mean(se)\n",
    "    \n",
    "    def valid_mse(self, y):\n",
    "        return mse(self, y)\n",
    "        \n",
    "\n",
    "def shared_dataset(data_xy, borrow=True, no_c=False):\n",
    "        \"\"\" Function that loads the dataset into shared variables\n",
    "        \"\"\"\n",
    "        data_x, data_y = data_xy[:2]\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                               dtype='float32'),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(np.asarray(data_y,\n",
    "                                               dtype='float32'),\n",
    "                                 borrow=borrow)\n",
    "        return shared_x, shared_y\n",
    "\n",
    "def train_nn(train_dataset, valid_dataset=None, n_hidden=20, learning_rate=0.01, n_epochs=10, batch_size=20, linear=False, mult_ys=True, rho=0, nesterov=True, mu=0, n_in=61, n_out=2):\n",
    "    \"\"\"\n",
    "    Demonstrate stochastic gradient descent optimization for a multilayer\n",
    "    perceptron\n",
    "\n",
    "    :type learning_rate: float\n",
    "    :param learning_rate: learning rate used (factor for the stochastic\n",
    "    gradient\n",
    "\n",
    "    :type n_epochs: int\n",
    "    :param n_epochs: maximal number of epochs to run the optimizer\n",
    "\n",
    "   \"\"\"\n",
    "    train_set_x, train_set_y = shared_dataset(train_dataset)\n",
    "    if valid_dataset:\n",
    "        valid_set_x, valid_set_y = shared_dataset(valid_dataset)\n",
    "    \n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    # BUILD ACTUAL MODEL #\n",
    "    ######################\n",
    "    print '... building the model'\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "    x = T.fmatrix('x')   # input data from visual neurons\n",
    "    if n_out == 1:\n",
    "        y = T.fvector('y') # ground truth\n",
    "    else:\n",
    "        y = T.fmatrix('y')  # ground truth\n",
    "\n",
    "    rng = np.random.RandomState(1234)\n",
    "\n",
    "    # construct the MLP class\n",
    "    if linear:\n",
    "        nn = Perceptron(rng=rng, input=x, n_in=n_in, n_out=n_out)\n",
    "    else:\n",
    "        nn = MLP(rng=rng, input=x, n_in=n_in, n_hidden=n_hidden, n_out=n_out)\n",
    "    \n",
    "    cost = nn.mse(y)\n",
    "    \n",
    "    def RMSprop(cost, params, learning_rate=0.001, rho=0.9, epsilon=1e-6, mu=0, nesterov=False):\n",
    "        gparams = T.grad(cost, params)\n",
    "        updates = []\n",
    "        for p, g in zip(params, gparams):\n",
    "            v = theano.shared(p.get_value() * 0.)\n",
    "            ms = theano.shared(p.get_value() * 0.)\n",
    "            ms_new = rho * ms + (1 - rho) * g ** 2\n",
    "            gradient_scaling = T.sqrt(ms_new + epsilon)\n",
    "            g = g / gradient_scaling\n",
    "            \"\"\"\n",
    "            (1) v_t = mu * v_t-1 - lr * gradient_f(params_t)\n",
    "            or\n",
    "            classic\n",
    "            (2) params_t = params_t-1 + v_t\n",
    "            nesterov\n",
    "            (7) params_t = params_t-1 + mu * v_t - lr * gradient_f(params_t-1)\n",
    "            (8) params_t = params_t-1 + mu**2 * v_t-1 - (1+mu) * lr * gradient_f(params_t-1)\n",
    "            \"\"\"\n",
    "            v_new = mu * v - (1 - mu) * learning_rate * g\n",
    "            if nesterov:\n",
    "                p_new = p + mu * v_new - (1 - mu) * learning_rate * g\n",
    "            else:\n",
    "                p_new = p + v_new\n",
    "            updates.append((ms, ms_new))\n",
    "            updates.append((v, v_new))\n",
    "            updates.append((p, p_new))\n",
    "                \n",
    "        return updates\n",
    "    \n",
    "    if rho:\n",
    "        updates = RMSprop(cost, nn.params, learning_rate=learning_rate, rho=rho, mu=mu, nesterov=nesterov)\n",
    "    else:\n",
    "        # compute the gradient of cost with respect to theta (sotred in params)\n",
    "        # the resulting gradients will be stored in a list gparams\n",
    "        gparams = [T.grad(cost, param) for param in nn.params]\n",
    "\n",
    "        # specify how to update the parameters of the model as a list of\n",
    "        # (variable, update expression) pairs\n",
    "\n",
    "        updates = [\n",
    "            (param, param - learning_rate * gparam)\n",
    "            for param, gparam in zip(nn.params, gparams)\n",
    "        ]\n",
    "    \n",
    "    def inspect_inputs(i, node, fn):\n",
    "        print i, node, \"input(s) value(s):\", [input[0] for input in fn.inputs]\n",
    "\n",
    "    def inspect_outputs(i, node, fn):\n",
    "        print \"output(s) value(s):\", [output[0] for output in fn.outputs]\n",
    "\n",
    "    # compiling a Theano function `train_model` that returns the cost, but\n",
    "    # in the same time updates the parameter of the model based on the rules\n",
    "    # defined in `updates`\n",
    "    train_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if mult_ys:\n",
    "        valid_mse = nn.valid_mse(y)\n",
    "    else:\n",
    "        valid_mse = cost\n",
    "    \n",
    "    validate_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=valid_mse,\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size:(index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size:(index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ###############\n",
    "    # TRAIN MODEL #\n",
    "    ###############\n",
    "    print '... training'\n",
    "\n",
    "    epoch = 0 \n",
    "\n",
    "    if valid_dataset:\n",
    "        valid_mse = np.zeros(n_epochs)\n",
    "\n",
    "    while (epoch < n_epochs):\n",
    "        for minibatch_index in xrange(n_train_batches):\n",
    "            \n",
    "            minibatch_avg_cost = train_model(minibatch_index)\n",
    "            \n",
    "        if valid_dataset:\n",
    "            validation_losses = [validate_model(i) for i in xrange(n_valid_batches)]\n",
    "            this_validation_loss = np.mean(validation_losses)\n",
    "            valid_mse[epoch] = this_validation_loss\n",
    "            print(\n",
    "                'epoch %i, validation error %f' %\n",
    "                (\n",
    "                    epoch,\n",
    "                    this_validation_loss,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        epoch = epoch + 1\n",
    "\n",
    "    if valid_dataset:\n",
    "        return nn, x, valid_mse\n",
    "    return nn, x\n",
    "\n",
    "def test_nn(nn, nnx, test_data):\n",
    "    print 'testing'\n",
    "    test_batch_size = 1\n",
    "    test_set_x, test_set_y = shared_dataset(test_data)\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "    x = nnx   # input data from visual neurons\n",
    "    test_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=nn.y_pred,\n",
    "        givens={\n",
    "            x: test_set_x[index * test_batch_size: (index + 1) * test_batch_size]\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    true_ys = test_set_y.get_value()\n",
    "    pred_ys = np.zeros((len(true_ys), 2))\n",
    "    for i in range(len(true_ys)):\n",
    "        pred_ys[i] = test_model(i)\n",
    "        #print test_model(i)[0], true_ys[i]\n",
    "        #print test_model(i)[0] * 90, true_ys[i]\n",
    "    \n",
    "    #print nn.get_params()\n",
    "    return pred_ys, true_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print df[df.qty1 == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0f725ab1486d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m19998\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_data_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m297\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.00001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrhos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_testset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_1 = generate_testset(19998, discrete_c=3, low=.3, high=.7)\n",
    "valid_data_1 = generate_testset(297, discrete_c=3, low=.3, high=.7)\n",
    "lrs = [.01, .005, .001, .0005, .0001, .00001]\n",
    "rhos = [0, .75, .9, .95, .99, .999]\n",
    "mus = [0, .75, .9, .95, .99, .999]\n",
    "nests = [True, False]\n",
    "nrows = len(lrs) * len(rhos) * len(mus) * len(nests)\n",
    "nn_df = pd.DataFrame(index=np.arange(0, nrows), columns=('lr', 'rho', 'mu', 'nest', 'valid_nn') )\n",
    "nns = {}\n",
    "ind = 0\n",
    "for lr in lrs:\n",
    "    for rho in rhos:\n",
    "        for mu in mus:\n",
    "            for n in nests:\n",
    "                nn, nnx, valid_nn = train_nn(train_data_1, valid_dataset=valid_data_1, n_hidden=20, learning_rate=lr, n_epochs=100, rho=rho, mu=mu, nesterov=n)\n",
    "                nn_df.loc[ind] = [lr, rho, mu, n, valid_nn[99]]\n",
    "                nns[lr, rho, mu, n] = nn, nnx, valid_nn\n",
    "                ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
