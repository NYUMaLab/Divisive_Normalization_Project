{
 "metadata": {
  "name": "",
  "signature": "sha256:eb7c05f66947e623c371e255f0685510228f2cdd4c3a56723f75470dd376c55e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import pystan\n",
      "import matplotlib.pyplot as plt\n",
      "import argparse\n",
      "from scipy.stats import poisson\n",
      "import matplotlib.patches as mpatches\n",
      "from functools import partial\n",
      "\n",
      "nneuron = 61\n",
      "min_angle = -90\n",
      "max_angle = 90\n",
      "sprefs = np.linspace(min_angle, max_angle, nneuron)\n",
      "ndata = 3000\n",
      "eps = np.finfo(np.float64).eps\n",
      "\n",
      "r_max = 10\n",
      "sigtc_sq = float(10**2)\n",
      "sigtc = 10\n",
      "c_50 = 13.1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def random_s(ndata, sort):\n",
      "    s = np.random.rand(2, ndata) * 120 - 60\n",
      "    if sort:\n",
      "        s = np.sort(s, axis=0)\n",
      "    return s[0], s[1]\n",
      "\n",
      "def generate_trainset(ndata, r_max=10):\n",
      "    s_0, s_1 = random_s(ndata, True)\n",
      "    c_0, c_1 = np.ones((2, ndata)) * .5\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c\n",
      "\n",
      "def generate_trainset_c(ndata, low=.3, high=.7, r_max=10):\n",
      "    s_0, s_1 = random_s(ndata, True)\n",
      "    c_0, c_1 = np.concatenate((np.ones((2, ndata/2)) * low, np.ones((2, ndata/2)) * high), axis=1)\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c\n",
      "\n",
      "def generate_testset_c(ndata, low=.3, high=.7, r_max=10):\n",
      "    s_0, s_1 = random_s(ndata, True)\n",
      "    c_range = high - low\n",
      "    c_0, c_1 = np.random.rand(2, ndata) * c_range + low\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c\n",
      "    \n",
      "def generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, noise, sort, s_0, s_1, c_0, c_1):\n",
      "    c_rms = np.sqrt(np.square(c_0) + np.square(c_1))\n",
      "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
      "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
      "    stim_0 = c_0 * s_0t.T\n",
      "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
      "    stim_1 = c_1 * s_1t.T\n",
      "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
      "    r = r_max * (stim_0 + stim_1)\n",
      "    r = r.T\n",
      "    s = np.array((s_0, s_1)).T\n",
      "    s = s/90\n",
      "    c = np.array((c_0, c_1)).T\n",
      "    if noise == \"poisson\":\n",
      "        r = np.random.poisson(r) + 0.0\n",
      "    return r, s, c\n",
      "\n",
      "def generate_testset(stim_0, stim_1, ndata, con_0=.5, con_1=.5, constant_c=True, discrete_c=None, low=.5, high=.5, r_max=10):\n",
      "    #c_0, c_1 = np.ones((2, ndata)) * .5\n",
      "    if constant_c:\n",
      "        c_0 = np.ones(ndata) * con_0\n",
      "        c_1 = np.ones(ndata) * con_1\n",
      "    else:\n",
      "        c_range = high - low\n",
      "        if discrete_c:\n",
      "            cs = np.linspace(low, high, discrete_c)\n",
      "            perm_cs = list(product(cs, cs))\n",
      "            c_0, c_1 = np.repeat(perm_cs, ndata/(discrete_c**2), axis=0).T\n",
      "            print ndata/(discrete_c**2), \"trials per contrast level\"\n",
      "            if ndata%(discrete_c**2) != 0:\n",
      "                print \"Not divisible, only generated\", ndata / (discrete_c**2) * (discrete_c**2), \"trials\"\n",
      "            ndata = ndata / (discrete_c**2) * (discrete_c**2)\n",
      "        else:\n",
      "            c_0, c_1 = np.random.rand(2, ndata) * c_range + low\n",
      "    s_0, s_1 = np.ones((2, ndata))\n",
      "    s_0 = s_0 * stim_0\n",
      "    s_1 = s_1 * stim_1\n",
      "    r, s, c = generate_popcode_data(ndata, nneuron, sigtc_sq, c_50, r_max, \"poisson\", True, s_0, s_1, c_0, c_1)\n",
      "    return r, s, c\n",
      "\n",
      "def random_c(ndata, ndims, low, high, sort):\n",
      "    c_range = high - low\n",
      "    if ndims == 1:\n",
      "        c = np.random.rand(ndims, ndata)[0] * c_range + low\n",
      "    else:\n",
      "        c = np.random.rand(ndims, ndata) * c_range + low\n",
      "    if sort:\n",
      "        c = np.sort(c, axis=0)\n",
      "    return c\n",
      "\n",
      "def generate_trainset_cat(ndata, low=.3, high=1.3, crange=.5, r_max=10):\n",
      "    numvec = np.random.binomial(1, .5, size=ndata).astype(int)\n",
      "    c_0 = random_c(ndata, 1, high, high+crange, True)\n",
      "    c_1 = random_c(ndata, 1, low, low+crange, True)\n",
      "    s_0, s_1 = np.random.rand(2, ndata) * 120 - 60\n",
      "    r, numvec, s, c  = generate_popcode_data_cat(ndata, numvec, nneuron, sigtc_sq, c_50, r_max, \"poisson\", s_0, s_1, c_0, c_1)\n",
      "    y = s[range(ndata), numvec]\n",
      "    return r, y, s, c, numvec \n",
      "    \n",
      "def generate_popcode_data_cat(ndata, numvec, nneuron, sigtc_sq, c_50, r_max, noise, s_0, s_1, c_0, c_1):\n",
      "    c0vec = c_0 * np.ones(ndata)\n",
      "    c1vec = c_1 * numvec\n",
      "    c_rms = np.sqrt(np.square(c0vec) + np.square(c1vec))\n",
      "    sprefs_data = np.tile(sprefs, (ndata, 1))\n",
      "    s_0t = np.exp(-np.square((np.transpose(np.tile(s_0, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
      "    stim_0 = c0vec * s_0t.T\n",
      "    s_1t = np.exp(-np.square((np.transpose(np.tile(s_1, (nneuron, 1))) - sprefs_data))/(2 * sigtc_sq))\n",
      "    stim_1 = c1vec * s_1t.T\n",
      "    #r = r_max * (stim_0 + stim_1)/(c_50 + c_rms)\n",
      "    r = r_max * (stim_0 + stim_1)/(c_rms)\n",
      "    #r = r_max * (stim_0 + stim_1)\n",
      "    r = r.T\n",
      "    s = np.array((s_0, s_1)).T\n",
      "    s = s/90\n",
      "    c = np.array((c_0, c_1)).T\n",
      "    if noise == \"poisson\":\n",
      "        r = np.random.poisson(r) + 0.0\n",
      "    return r, numvec, s, c "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "generate_trainset_cat(10, low=.3, high=1.3, crange=.4, r_max=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   1.,   0.,   1.,   2.,   2.,   2.,   4.,\n",
        "           6.,   5.,   8.,  14.,  10.,   7.,   7.,   4.,   3.,   1.,   3.,\n",
        "           1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   1.,   1.,   1.,   3.,   5.,   0.,   4.,   2.,   7.,\n",
        "           3.,   5.,   7.,   9.,   4.,  11.,   8.,   8.,   3.,   4.,   0.,\n",
        "           1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   1.,   2.,   3.,   7.,   8.,  11.,   6.,  13.,  10.,   7.,\n",
        "           9.,   4.,   4.,   2.,   2.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   2.,\n",
        "           4.,   3.,  10.,  12.,  11.,  15.,   7.,   3.,   5.,   3.,   4.,\n",
        "           4.,   2.,   2.,   2.,   4.,   4.,   2.,   2.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
        "           5.,   7.,   9.,   7.,   9.,  13.,  10.,   5.,   5.,   1.,   2.,\n",
        "           1.,   1.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   1.,   0.,   1.,   5.,   5.,   9.,   9.,\n",
        "          10.,  11.,  10.,   6.,   5.,   4.,   3.,   2.,   1.,   1.,   1.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   1.,   0.,   0.,   2.,   2.,   8.,   5.,\n",
        "           8.,  12.,   8.,  14.,   8.,   6.,   5.,   2.,   4.,   0.,   0.,\n",
        "           1.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   1.,   1.,   3.,   4.,   2.,   5.,   7.,  11.,   8.,   9.,\n",
        "           8.,  10.,   7.,   9.,   5.,   5.,   4.,   3.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   1.,   0.,   0.,   2.,   1.,   8.,   6.,   8.,   9.,  12.,\n",
        "          15.,  14.,   5.,   1.,   6.,   4.,   1.,   0.,   0.,   1.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.],\n",
        "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
        "           0.,   0.,   4.,   0.,   2.,   3.,   6.,   3.,   1.,   1.,   3.,\n",
        "           1.,   0.,   0.,   0.,   0.,   1.,   3.,   0.,   1.,   4.,   5.,\n",
        "           7.,   8.,   5.,   9.,  10.,   4.,   5.,   3.,   2.,   2.,   3.,\n",
        "           0.,   0.,   0.,   0.,   0.,   0.]]),\n",
        " array([ 0.19847438, -0.41183528,  0.38009565,  0.59877132,  0.62721675,\n",
        "         0.50181274,  0.51836823, -0.3155575 , -0.66486596, -0.01688062]),\n",
        " array([[ 0.19847438, -0.0392923 ],\n",
        "        [-0.14519444, -0.41183528],\n",
        "        [ 0.38009565, -0.43667049],\n",
        "        [ 0.24668637,  0.59877132],\n",
        "        [ 0.62721675,  0.44799526],\n",
        "        [ 0.50181274,  0.3824658 ],\n",
        "        [ 0.51836823, -0.22111239],\n",
        "        [-0.24654837, -0.3155575 ],\n",
        "        [-0.66486596,  0.53078177],\n",
        "        [ 0.55167758, -0.01688062]]),\n",
        " array([[ 1.33997016,  0.30595704],\n",
        "        [ 1.42813058,  0.32208689],\n",
        "        [ 1.45353528,  0.34454601],\n",
        "        [ 1.50820046,  0.43048618],\n",
        "        [ 1.51062661,  0.48411485],\n",
        "        [ 1.53293791,  0.50294945],\n",
        "        [ 1.53954775,  0.61746677],\n",
        "        [ 1.59680912,  0.64969037],\n",
        "        [ 1.60334699,  0.65704797],\n",
        "        [ 1.65140577,  0.68619767]]),\n",
        " array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1]))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Multilayer ReLU net\n",
      "\"\"\"\n",
      "\n",
      "def relu(x):\n",
      "    return theano.tensor.switch(x<0, 0, x)\n",
      "\n",
      "class HiddenLayer(object):\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None,\n",
      "                 activation=T.nnet.sigmoid):\n",
      "        \"\"\"\n",
      "        Typical hidden layer of a MLP: units are fully-connected and have\n",
      "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
      "        and the bias vector b is of shape (n_out,).\n",
      "\n",
      "        :type rng: np.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.dmatrix\n",
      "        :param input: a symbolic tensor of shape (n_examples, n_in)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: dimensionality of input\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of hidden units\n",
      "\n",
      "        :type activation: theano.Op or function\n",
      "        :param activation: Non linearity to be applied in the hidden\n",
      "                           layer\n",
      "        \"\"\"\n",
      "        self.input = input\n",
      "        if W is None:\n",
      "            W_values = (1/np.sqrt(n_in)) * np.random.randn(n_in, n_out)\n",
      "            \n",
      "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
      "\n",
      "        if b is None:\n",
      "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
      "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
      "\n",
      "        self.W = W\n",
      "        self.b = b\n",
      "\n",
      "        lin_output = T.dot(input, self.W) + self.b\n",
      "        self.output = (\n",
      "            lin_output if activation is None\n",
      "            else activation(lin_output)\n",
      "        )\n",
      "        # parameters of the model\n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "class MLP(object):\n",
      "\n",
      "\n",
      "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
      "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
      "\n",
      "        :type rng: np.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.TensorType\n",
      "        :param input: symbolic variable that describes the input of the\n",
      "        architecture (one minibatch)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: number of input units, the dimension of the space in\n",
      "        which the datapoints lie\n",
      "\n",
      "        :type n_hidden: int\n",
      "        :param n_hidden: number of hidden units\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of output units, the dimension of the space in\n",
      "        which the labels lie\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        self.hiddenLayer1 = HiddenLayer(\n",
      "            rng=rng,\n",
      "            input=input,\n",
      "            n_in=n_in,\n",
      "            n_out=n_hidden,\n",
      "            #activation=T.nnet.sigmoid\n",
      "            activation=relu\n",
      "        )\n",
      "        \n",
      "        self.hiddenLayer2 = HiddenLayer(\n",
      "            rng=rng,\n",
      "            input=self.hiddenLayer1.output,\n",
      "            n_in=n_hidden,\n",
      "            n_out=n_out,\n",
      "            #activation=relu\n",
      "            activation=None\n",
      "        )\n",
      "        \n",
      "        self.y_pred = self.hiddenLayer2.output\n",
      "        \n",
      "        # the parameters of the model are the parameters of the two layers it is made out of\n",
      "        self.params = self.hiddenLayer1.params + self.hiddenLayer2.params\n",
      "    \n",
      "    def get_params(self):\n",
      "\n",
      "        params = {}\n",
      "        for param in self.params:\n",
      "            name = param.name\n",
      "            if name in params:\n",
      "                name = name, 2\n",
      "            params[name] = param.get_value()\n",
      "        return params\n",
      "    \n",
      "    def mse(self, y):\n",
      "        # error between output and target\n",
      "        if y.ndim == 1:\n",
      "            se = (self.y_pred.T - y)**2\n",
      "        else:\n",
      "            se = T.sum((self.y_pred - y)**2, axis=1)\n",
      "        return T.mean(se)\n",
      "        \n",
      "    \n",
      "    def valid_mse(self, y):\n",
      "        if y.ndim == 1:\n",
      "            se = (self.y_pred.T * 90 - y * 90)**2\n",
      "        else:\n",
      "            se = T.sum((self.y_pred * 90 - y * 90)**2, axis=1)\n",
      "        return T.mean(se)\n",
      "\n",
      "def shared_dataset(data_xy, borrow=True, no_c=False):\n",
      "        \"\"\" Function that loads the dataset into shared variables\n",
      "        \"\"\"\n",
      "        data_x, data_y = data_xy[:2]\n",
      "        shared_x = theano.shared(np.asarray(data_x,\n",
      "                                               dtype='float32'),\n",
      "                                 borrow=borrow)\n",
      "        shared_y = theano.shared(np.asarray(data_y,\n",
      "                                               dtype='float32'),\n",
      "                                 borrow=borrow)\n",
      "        return shared_x, shared_y\n",
      "\n",
      "def train_nn(train_dataset, valid_dataset=None, n_hidden=20, learning_rate=0.01, n_epochs=10, batch_size=20, linear=False, mult_ys=True, rho=0, nesterov=True, momentum=0, n_in=61, n_out=2):\n",
      "    \"\"\"\n",
      "    Demonstrate stochastic gradient descent optimization for a multilayer\n",
      "    perceptron\n",
      "\n",
      "    :type learning_rate: float\n",
      "    :param learning_rate: learning rate used (factor for the stochastic\n",
      "    gradient\n",
      "\n",
      "    :type n_epochs: int\n",
      "    :param n_epochs: maximal number of epochs to run the optimizer\n",
      "\n",
      "   \"\"\"\n",
      "    train_set_x, train_set_y = shared_dataset(train_dataset)\n",
      "    if valid_dataset:\n",
      "        valid_set_x, valid_set_y = shared_dataset(valid_dataset)\n",
      "    \n",
      "    # compute number of minibatches for training, validation and testing\n",
      "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "    \n",
      "    \n",
      "    ######################\n",
      "    # BUILD ACTUAL MODEL #\n",
      "    ######################\n",
      "    print '... building the model'\n",
      "\n",
      "    # allocate symbolic variables for the data\n",
      "    index = T.lscalar()  # index to a [mini]batch\n",
      "    x = T.fmatrix('x')   # input data from visual neurons\n",
      "    if n_out == 1:\n",
      "        y = T.fvector('y') # ground truth\n",
      "    else:\n",
      "        y = T.fmatrix('y')  # ground truth\n",
      "\n",
      "    rng = np.random.RandomState(1234)\n",
      "\n",
      "    # construct the MLP class\n",
      "    if linear:\n",
      "        nn = Perceptron(rng=rng, input=x, n_in=n_in, n_out=n_out)\n",
      "    else:\n",
      "        nn = MLP(rng=rng, input=x, n_in=n_in, n_hidden=n_hidden, n_out=n_out)\n",
      "    \n",
      "    cost = nn.mse(y)\n",
      "    \n",
      "    def RMSprop(cost, params, learning_rate=0.001, rho=0.9, epsilon=1e-6, mu=0, nesterov=False):\n",
      "        gparams = T.grad(cost, params)\n",
      "        updates = []\n",
      "        for p, g in zip(params, gparams):\n",
      "            v = theano.shared(p.get_value() * 0.)\n",
      "            ms = theano.shared(p.get_value() * 0.)\n",
      "            ms_new = rho * ms + (1 - rho) * g ** 2\n",
      "            gradient_scaling = T.sqrt(ms_new + epsilon)\n",
      "            g = g / gradient_scaling\n",
      "            \"\"\"\n",
      "            (1) v_t = mu * v_t-1 - lr * gradient_f(params_t)\n",
      "            or\n",
      "            classic\n",
      "            (2) params_t = params_t-1 + v_t\n",
      "            nesterov\n",
      "            (7) params_t = params_t-1 + mu * v_t - lr * gradient_f(params_t-1)\n",
      "            (8) params_t = params_t-1 + mu**2 * v_t-1 - (1+mu) * lr * gradient_f(params_t-1)\n",
      "            \"\"\"\n",
      "            v_new = mu * v - (1 - mu) * learning_rate * g\n",
      "            if nesterov:\n",
      "                p_new = p + mu * v_new - (1 - mu) * learning_rate * g\n",
      "            else:\n",
      "                p_new = p + v_new\n",
      "            updates.append((ms, ms_new))\n",
      "            updates.append((v, v_new))\n",
      "            updates.append((p, p_new))\n",
      "                \n",
      "        return updates\n",
      "    \n",
      "    if rho:\n",
      "        updates = RMSprop(cost, nn.params, learning_rate=learning_rate, rho=rho, mu=momentum, nesterov=nesterov)\n",
      "    else:\n",
      "        # compute the gradient of cost with respect to theta (sotred in params)\n",
      "        # the resulting gradients will be stored in a list gparams\n",
      "        gparams = [T.grad(cost, param) for param in nn.params]\n",
      "\n",
      "        # specify how to update the parameters of the model as a list of\n",
      "        # (variable, update expression) pairs\n",
      "\n",
      "        updates = [\n",
      "            (param, param - learning_rate * gparam)\n",
      "            for param, gparam in zip(nn.params, gparams)\n",
      "        ]\n",
      "    \n",
      "    def inspect_inputs(i, node, fn):\n",
      "        print i, node, \"input(s) value(s):\", [input[0] for input in fn.inputs]\n",
      "\n",
      "    def inspect_outputs(i, node, fn):\n",
      "        print \"output(s) value(s):\", [output[0] for output in fn.outputs]\n",
      "\n",
      "    # compiling a Theano function `train_model` that returns the cost, but\n",
      "    # in the same time updates the parameter of the model based on the rules\n",
      "    # defined in `updates`\n",
      "    train_model = theano.function(\n",
      "        inputs=[index],\n",
      "        outputs=cost,\n",
      "        updates=updates,\n",
      "        givens={\n",
      "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
      "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
      "        }\n",
      "    )\n",
      "    \n",
      "    if mult_ys:\n",
      "        valid_mse = nn.valid_mse(y)\n",
      "    else:\n",
      "        valid_mse = cost\n",
      "    \n",
      "    validate_model = theano.function(\n",
      "        inputs=[index],\n",
      "        outputs=valid_mse,\n",
      "        givens={\n",
      "            x: valid_set_x[index * batch_size:(index + 1) * batch_size],\n",
      "            y: valid_set_y[index * batch_size:(index + 1) * batch_size]\n",
      "        }\n",
      "    )\n",
      "\n",
      "    ###############\n",
      "    # TRAIN MODEL #\n",
      "    ###############\n",
      "    print '... training'\n",
      "\n",
      "    start_time = time.clock()\n",
      "\n",
      "    epoch = 0 \n",
      "    done_looping = False\n",
      "    \n",
      "    if valid_dataset:\n",
      "        valid_mse = np.zeros(n_epochs)\n",
      "\n",
      "    while (epoch < n_epochs) and (not done_looping):\n",
      "        for minibatch_index in xrange(n_train_batches):\n",
      "            \n",
      "            minibatch_avg_cost = train_model(minibatch_index)\n",
      "            \n",
      "        if valid_dataset:\n",
      "            validation_losses = [validate_model(i) for i in xrange(n_valid_batches)]\n",
      "            this_validation_loss = np.mean(validation_losses)\n",
      "            valid_mse[epoch] = this_validation_loss\n",
      "            print(\n",
      "                'epoch %i, validation error %f' %\n",
      "                (\n",
      "                    epoch,\n",
      "                    this_validation_loss,\n",
      "                )\n",
      "            )\n",
      "            \n",
      "        epoch = epoch + 1\n",
      "\n",
      "    end_time = time.clock()\n",
      "    \n",
      "    if valid_dataset:\n",
      "        return nn, x, valid_mse\n",
      "    return nn, x\n",
      "\n",
      "def test_nn(nn, nnx, test_data):\n",
      "    print 'testing'\n",
      "    test_batch_size = 1\n",
      "    test_set_x, test_set_y = shared_dataset(test_data)\n",
      "    index = T.lscalar()  # index to a [mini]batch\n",
      "    x = nnx   # input data from visual neurons\n",
      "    test_model = theano.function(\n",
      "        inputs=[index],\n",
      "        outputs=nn.y_pred,\n",
      "        givens={\n",
      "            x: test_set_x[index * test_batch_size: (index + 1) * test_batch_size]\n",
      "        },\n",
      "    )\n",
      "    \n",
      "    true_ys = test_set_y.get_value()\n",
      "    pred_ys = np.zeros((len(true_ys), 2))\n",
      "    for i in range(len(true_ys)):\n",
      "        pred_ys[i] = test_model(i)\n",
      "        #print test_model(i)[0], true_ys[i]\n",
      "        #print test_model(i)[0] * 90, true_ys[i]\n",
      "    \n",
      "    #print nn.get_params()\n",
      "    return pred_ys, true_ys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "td_cat = generate_trainset_cat(20000, low=.3, high=1, crange=.2, r_max=10)\n",
      "vd_cat = generate_trainset_cat(3000, low=.3, high=1, crange=.2, r_max=10)\n",
      "nn_cat, nnx_cat, valid_mse_cat = train_nn(td_cat, valid_dataset=vd_cat, n_hidden=20, learning_rate=.0005, n_epochs=100, rho=.9, n_out=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... building the model\n",
        "... training"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 0, validation error 274.357814"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 1, validation error 123.817154"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2, validation error 92.710184"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3, validation error 77.288292"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4, validation error 67.689424"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5, validation error 61.679587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6, validation error 57.104877"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7, validation error 53.649460"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8, validation error 51.010307"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9, validation error 48.722324"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10, validation error 46.957902"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11, validation error 45.308484"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12, validation error 43.955511"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13, validation error 42.907963"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14, validation error 42.232418"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15, validation error 41.646011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16, validation error 41.136842"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17, validation error 40.714560"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18, validation error 40.459671"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19, validation error 40.237495"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20, validation error 39.948085"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 21, validation error 39.694829"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 22, validation error 39.656904"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 23, validation error 39.519062"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 24, validation error 39.419453"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 25, validation error 39.380420"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 26, validation error 39.413962"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 27, validation error 39.616356"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 28, validation error 39.683744"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 29, validation error 39.809801"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 30, validation error 39.888910"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 31, validation error 39.768425"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 32, validation error 39.824853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 33, validation error 39.810409"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 34, validation error 39.621362"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 35, validation error 39.662682"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 36, validation error 39.514664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 37, validation error 39.454798"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 38, validation error 39.476279"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 39, validation error 39.558137"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 40, validation error 39.393435"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 41, validation error 39.461397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 42, validation error 39.384446"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 43, validation error 39.593410"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 44, validation error 39.330718"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 45, validation error 39.363121"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 46, validation error 39.382189"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 47, validation error 39.505887"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 48, validation error 39.630875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 49, validation error 39.626722"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 50, validation error 39.612573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 51, validation error 39.606212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 52, validation error 39.537297"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 53, validation error 39.476742"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 54, validation error 39.476227"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 55, validation error 39.366673"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 56, validation error 39.432840"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 57, validation error 39.362253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 58, validation error 39.447187"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 59, validation error 39.489477"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 60, validation error 39.430509"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 61, validation error 39.273773"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 62, validation error 39.153023"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 63, validation error 39.090497"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 64, validation error 39.097054"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 65, validation error 39.019056"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 66, validation error 39.040333"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 67, validation error 39.104186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 68, validation error 39.009262"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 69, validation error 39.008606"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 70, validation error 38.982731"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 71, validation error 39.026239"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 72, validation error 39.052321"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 73, validation error 38.937093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 74, validation error 38.908121"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 75, validation error 38.757177"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 76, validation error 38.758180"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 77, validation error 38.751029"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 78, validation error 38.603249"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 79, validation error 38.612085"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 80, validation error 38.477439"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 81, validation error 38.478932"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 82, validation error 38.366951"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 83, validation error 38.299868"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 84, validation error 38.299289"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 85, validation error 38.299433"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 86, validation error 38.139110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 87, validation error 38.162666"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 88, validation error 38.157034"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 89, validation error 38.116852"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 90, validation error 38.051749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 91, validation error 38.070377"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 92, validation error 37.983765"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 93, validation error 38.006953"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 94, validation error 38.003720"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 95, validation error 37.936570"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 96, validation error 38.001555"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 97, validation error 38.093028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 98, validation error 37.821126"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 99, validation error 37.778022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}