{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson, kurtosis\n",
    "import matplotlib.patches as mpatches\n",
    "from functools import partial\n",
    "import pickle\n",
    "import os\n",
    "import demixing as dm\n",
    "from demixing import MLP, HiddenLayer\n",
    "\n",
    "nneuron = 61\n",
    "min_angle = -90\n",
    "max_angle = 90\n",
    "sprefs = np.linspace(min_angle, max_angle, nneuron)\n",
    "eps = np.finfo(np.float64).eps\n",
    "sigtc_sq = float(10**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nns = {}\n",
    "for i in range(0, 200):\n",
    "    file_name = 'output_nn_runs_2/nn_runs_2_' + str(i) + '.pkl'\n",
    "    if os.path.isfile(file_name):\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        nn, nnx, valid_mse, _, _ = pickle.load(pkl_file)\n",
    "        nns[i] = (nn, nnx, valid_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_v1 = {}\n",
    "posts_v2 = {}\n",
    "testsets = {}\n",
    "for s_i in range(90):\n",
    "    file_name = 'output_post_4/post_4_' + str(s_i) + '.pkl'\n",
    "    if os.path.isfile(file_name):\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        p, r, c, s, delta_s = pickle.load(pkl_file)\n",
    "        tc_i = tuple(c[i])\n",
    "        if tc_i in posts_v1:\n",
    "            posts_v1[tc_i] = np.append(posts_v1[tc_i], p['var_s1'])\n",
    "            posts_v2[tc_i] = np.append(posts_v2[tc_i], p['var_s2'])\n",
    "            testsets[tc_i] = np.append(testsets[tc_i], r, axis = 0)\n",
    "        else:\n",
    "            posts_v1[tc_i] = p['var_s1']\n",
    "            posts_v2[tc_i] = p['var_s2']\n",
    "            testsets[tc_i] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18"
     ]
    }
   ],
   "source": [
    "lin_corrs_ins = np.zeros((9, 200))\n",
    "lin_corrs_hus = np.zeros((9, 200))\n",
    "kurt_corrs = np.zeros((9, 200))\n",
    "sum_corrs = np.zeros((9, 200))\n",
    "\n",
    "lin_corrs_ins_all = np.zeros(200)\n",
    "lin_corrs_hus_all = np.zeros(200)\n",
    "kurt_corrs_all = np.zeros(200)\n",
    "sum_corrs_all = np.zeros(200)\n",
    "\n",
    "keys = posts_v1.keys()     \n",
    "for i in range(200):\n",
    "    print i\n",
    "    nn, nnx, valid_mse = nns[i]\n",
    "    validset_ins = {}\n",
    "    train_ins_0 = []\n",
    "    train_ins_1 = []\n",
    "    valid_ins_0 = []\n",
    "    valid_ins_1 = []\n",
    "    validset_hus = {}\n",
    "    train_hus_0 = []\n",
    "    train_hus_1 = []\n",
    "    valid_hus_0 = []\n",
    "    valid_hus_1 = []\n",
    "    for k in range(len(keys)):\n",
    "        k_i = keys[k]\n",
    "        x = testsets[k_i]\n",
    "        y = np.array((1/posts_v1[k_i], 1/posts_v2[k_i])).T\n",
    "        inds = range(len(x))\n",
    "        np.random.shuffle(inds)\n",
    "        x_shuf = x[inds]\n",
    "        y_shuf = y[inds]\n",
    "        x_hus = dm.get_hu_responses(x_shuf, nn)  \n",
    "        validset_ins[k] = x_shuf[0:2000], y_shuf[0:2000]\n",
    "        validset_hus[k] = x_hus[0:2000], y_shuf[0:2000]\n",
    "        valid_ins_0.append(x_shuf[0:2000])\n",
    "        valid_ins_1.append(y_shuf[0:2000])\n",
    "        valid_hus_0.append(x_hus[0:2000])\n",
    "        valid_hus_1.append(y_shuf[0:2000])\n",
    "        train_ins_0.append(x_shuf[2000:])\n",
    "        train_ins_1.append(y_shuf[2000:])\n",
    "        train_hus_0.append(x_hus[2000:])\n",
    "        train_hus_1.append(y_shuf[2000:])\n",
    "    trainset_ins_all = np.concatenate(train_ins_0), np.concatenate(train_ins_1)\n",
    "    trainset_hus_all = np.concatenate(train_hus_0), np.concatenate(train_hus_1)\n",
    "    validset_ins_all = np.concatenate(valid_ins_0), np.concatenate(valid_ins_1)\n",
    "    validset_hus_all = np.concatenate(valid_hus_0), np.concatenate(valid_hus_1) \n",
    "\n",
    "    weights_ins = np.linalg.lstsq(trainset_ins_all[0], trainset_ins_all[1])[0]\n",
    "    weights_hus = np.linalg.lstsq(trainset_hus_all[0], trainset_hus_all[1])[0]\n",
    "    for v in range(len(validset_hus)):\n",
    "        hus, vpost = validset_hus[v]\n",
    "        inputs, vpost = validset_ins[v]\n",
    "        lin_preds_hus = np.dot(hus, weights_hus)\n",
    "        lin_preds_ins = np.dot(inputs, weights_ins)\n",
    "        kurt_preds = kurtosis(hus, axis=1)\n",
    "        sum_preds = np.sum(hus, axis=1)\n",
    "        vp = np.concatenate((vpost.T[0], vpost.T[1]))\n",
    "        lin_preds_ins = np.concatenate((lin_preds_ins.T[0], lin_preds_ins.T[1]))\n",
    "        lin_preds_hus = np.concatenate((lin_preds_hus.T[0], lin_preds_hus.T[1]))\n",
    "        kurt_preds = np.concatenate((kurt_preds, kurt_preds))\n",
    "        sum_preds = np.concatenate((sum_preds, sum_preds))\n",
    "\n",
    "        lin_corrs_ins[v][i] = np.corrcoef(vp, lin_preds_ins)[0, 1]\n",
    "        lin_corrs_hus[v][i] = np.corrcoef(vp, lin_preds_hus)[0, 1]\n",
    "        kurt_corrs[v][i] = np.corrcoef(vp, kurt_preds)[0, 1]\n",
    "        sum_corrs[v][i] = np.corrcoef(vp, sum_preds)[0, 1]\n",
    "    \n",
    "    hus, vpost = validset_hus_all\n",
    "    inputs, vpost = validset_ins_all\n",
    "    lin_preds_ins = np.dot(inputs, weights_ins)\n",
    "    lin_preds_hus = np.dot(hus, weights_hus)\n",
    "    kurt_preds = kurtosis(hus, axis=1)\n",
    "    sum_preds = np.sum(hus, axis=1)\n",
    "    vp = np.concatenate((vpost.T[0], vpost.T[1]))\n",
    "    lin_preds_ins = np.concatenate((lin_preds_ins.T[0], lin_preds_ins.T[1]))\n",
    "    lin_preds_hus = np.concatenate((lin_preds_hus.T[0], lin_preds_hus.T[1]))\n",
    "    kurt_preds = np.concatenate((kurt_preds, kurt_preds))\n",
    "    sum_preds = np.concatenate((sum_preds, sum_preds))\n",
    "\n",
    "    lin_corrs_ins_all[i] = np.corrcoef(vp, lin_preds_ins)[0, 1]\n",
    "    lin_corrs_hus_all[i] = np.corrcoef(vp, lin_preds_hus)[0, 1]\n",
    "    kurt_corrs_all[i] = np.corrcoef(vp, kurt_preds)[0, 1]\n",
    "    sum_corrs_all[i] = np.corrcoef(vp, sum_preds)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(len(lin_corrs1), sharex=True, sharey=True)\n",
    "for i in range(len(lin_corrs1)):\n",
    "    ax[i].hist(lin_corrs_hus[0:200][i] - lin_corrs_ins[0:200][i], 10, facecolor='k', alpha=0.75)\n",
    "    ax[i].yaxis.set_ticks_position('left')\n",
    "    ax[i].xaxis.set_ticks_position('bottom')\n",
    "    ax[i].set_title(keys[i])\n",
    "ax[4].set_ylabel('# sims', fontsize=30)\n",
    "ax[8].set_xlabel('Difference in correlations', fontsize=30)\n",
    "f.set_size_inches(10,15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, sharex=True, sharey=True)\n",
    "ax.hist(lin_corrs_hus_all[0:200] - lin_corrs_ins_all[0:200], 10, facecolor='k', alpha=0.75)\n",
    "ax.set_ylabel('# sims', fontsize=30)\n",
    "ax.set_xlabel('Difference in correlation', fontsize=30)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nns_cov = {}\n",
    "for i in range(201):\n",
    "    file_name = 'output_nn_runs_cov/nn_runs_2_' + str(i) + '.pkl'\n",
    "    if os.path.isfile(file_name):\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        nn, nnx, valid_mse, _, _ = pickle.load(pkl_file)\n",
    "        nns_cov[i] = (nn, nnx, valid_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
